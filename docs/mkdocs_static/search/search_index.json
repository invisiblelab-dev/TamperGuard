{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Modular IO Library","text":"<p>A high-performance, modular I/O library for C applications featuring pluggable storage layers, data integrity verification, compression, and flexible configuration options.</p>"},{"location":"index.html#project-structure","title":"Project Structure","text":"<pre><code>\u251c\u2500\u2500 \ud83d\udcc1 layers/              # Pluggable I/O layers\n\u251c\u2500\u2500 \ud83d\udcc1 examples/            # Example applications  \n\u251c\u2500\u2500 \ud83d\udcc1 shared/              # Common utilities and types\n\u251c\u2500\u2500 \ud83d\udcc1 scripts/             # Scripts to test and benchmark\n\u251c\u2500\u2500 \ud83d\udcc1 tests/               # Unit and integration tests\n\u251c\u2500\u2500 \ud83d\udcc1 config/              # Configuration system\n\u251c\u2500\u2500 \ud83d\udcc1 lib/                 # External dependencies (submodules)\n\u2514\u2500\u2500 \ud83d\udcc4 config.toml.example  # Example configuration file\n</code></pre>"},{"location":"index.html#content","title":"Content","text":""},{"location":"index.html#core-components","title":"Core Components","text":"<ul> <li>Configuration System - TOML-based layer configuration</li> <li>Shared Components - Types, utilities, and hasher algorithms</li> </ul>"},{"location":"index.html#storage-layers","title":"Storage Layers","text":"<ul> <li>Local Layer - Local filesystem storage</li> <li>Remote Layer - Network-based remote storage</li> <li>Anti-Tampering Layer - Data integrity with SHA-256/SHA-512</li> <li>Compression Layer - LZ4/ZSTD compression support</li> <li>Encryption Layer - Data Encryption with AES-256-XTS</li> <li>Block Align Layer - Block-aligned I/O operations</li> <li>Demultiplexer Layer - Parallel multi-backend operations</li> <li>Read Cache Layer - Read caching using CacheLib</li> <li>Invisible Storage Layer - Invisible storage integration</li> </ul>"},{"location":"index.html#examples","title":"Examples","text":"<ul> <li>FUSE Example - FUSE filesystem implementation</li> <li>Invisible Example - Invisible Storage SDK example demonstration</li> <li>Storage Server Example - Network storage server</li> </ul>"},{"location":"index.html#testing","title":"Testing","text":"<ul> <li>Tests - Unit tests, integration tests, and testing infrastructure</li> </ul>"},{"location":"index.html#architecture","title":"Architecture","text":"<p>ModularIOLib exports a POSIX-compatible API. The library parses a user-provided layer configuration and dynamically stacks the various layers on top of each other. Each layer implements the same POSIX-compatible API, is fully independent, and remains agnostic of the layers above or below it.</p> <p>The bottom layer must be a persistence layer that handles actual data storage (e.g., local, s3_opendal, etc.).</p> <p>Here is an example of a possible configuration: <pre><code>flowchart TB\n    A[\"ModularIO Lib POSIX API\"] --&gt; B[\"Encryption\"]\n    B --&gt; C[\"Demultiplexer\"]\n    C --&gt; D[\"Local\"]\n    C --&gt; E[\"S3Opendal\"]\n\n    style A stroke-width:4px,stroke-dasharray: 0</code></pre></p>"},{"location":"index.html#quick-start","title":"Quick Start","text":""},{"location":"index.html#install","title":"Install","text":"<p>Make sure you have the following packages installed:</p>"},{"location":"index.html#ubuntudebian","title":"Ubuntu/Debian","text":"<pre><code>sudo apt install make pkg-config libglib2.0-dev gcc libssl-dev g++ libcurl4-openssl-dev\n</code></pre>"},{"location":"index.html#installing-libfuse","title":"Installing libfuse","text":"<p>In order to run the most complete example, you need to install libfuse.</p>"},{"location":"index.html#ubuntudebian_1","title":"Ubuntu/Debian","text":"<pre><code>sudo apt install libfuse3-dev fuse3\n</code></pre> <p>For more detailed installation instructions, see the libfuse documentation.</p> <p>Note: This project is only tested on Linux systems and is not guaranteed to work on macOS or other operating systems.</p>"},{"location":"index.html#install-rust","title":"Install rust","text":"<p>In order to use invisible-storage, you need to install rust (v1.88.0) and cargo (v1.88.0):</p>"},{"location":"index.html#ubuntudebian_2","title":"Ubuntu/Debian","text":"<pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsudo apt install rustc cargo\n</code></pre>"},{"location":"index.html#build-everything","title":"Build Everything","text":"<pre><code># Initialize submodules and build all components\ngit submodule update --init --recursive\n\nmake build BUILD_INVISIBLE=1 BUILD_CACHELIB=1\n# or to build without invisible storage (S3 and Solana support)\n# make build\n</code></pre>"},{"location":"index.html#configuration","title":"Configuration","text":"<p>Copy and customize the example configuration:</p> <pre><code>cp config.toml.example config.toml\n# Edit config.toml to define your layer architecture (see Configuration Example below)\n</code></pre>"},{"location":"index.html#simple-configuration","title":"Simple Configuration","text":"<p>The simplest configuration, which behaves as a passthrough, would look like this: <pre><code>root = \"local_layer\"\nlog_mode = \"debug\"\n\n[local_layer]\ntype = \"local\"\n</code></pre></p>"},{"location":"index.html#encryption-configuration-example","title":"Encryption Configuration Example","text":"<p>A simple configuration which performs encryption and stores locally (more about it here): <pre><code>root = \"block_align\"\nlog_mode = \"debug\"\n\n[block_align]\ntype = \"block_align\"\nblock_size = 262144 // 256kb\nnext = \"encryption_layer\"\n\n[encryption_layer]\ntype = \"encryption\"\nblock_size = 262144 // 256kb\nencryption_key = \"1234567890123456789012345678901234567890234567890123456789012345\"\nnext = \"local_layer\"\n\n[local_layer]\ntype = \"local\"\n</code></pre></p>"},{"location":"index.html#anti-tampering-configuration-example","title":"Anti-Tampering Configuration Example","text":"<p>The following shows a complete example config file demonstrating a multi-layer architecture with anti-tampering, demultiplexer, and blockchain (solana)/s3 to store hashes:</p> <pre><code>root = \"anti_tampering_layer\"\nlog_mode = \"debug\" # options (case insensitive): disabled, screen, error, warn, info, debug #\n\n[anti_tampering_layer]\ntype = \"anti_tampering\"\nhashes_storage = \"/home/user/Modular-IO-Lib/examples/fuse/hashes\" # Note: Use your absolute path here #\nhash_layer = \"demultiplexer_layer\"\ndata_layer = \"local_layer\"\nalgorithm = \"sha256\" # options (case insensitive): sha256, sha512 - defaults to sha256 if not specified #\n\n[demultiplexer_layer]\ntype = \"demultiplexer\"\nlayers = [\"s3_layer\", \"solana_layer\"]\n\n[demultiplexer_layer.options]\nenforced_layers = [\"s3_layer\"]\npassthrough_writes = [\"solana_layer\"]\n\n[local_layer]\ntype = \"local\"\n\n[s3_layer]\ntype = \"s3_opendal\"\nendpoint = \"some_endpoint\"\naccess_key_id = \"some_key_id\"\nsecret_access_key = \"some_secret_key\"\nbucket = \"some_bucket\"\nregion = \"some_region\"\nroot = \"some_root\"\n\n[solana_layer]\ntype = \"solana\"\nkeypair_path= \"some_keypair_path\"\nrpc_url = \"some_rpc_url\"\n</code></pre> <p>This example configuration demonstrates:</p> <ul> <li>Root Layer: <code>anti_tampering_layer</code> as the entry point</li> <li>Security Layer: Anti-tampering with SHA-256 hashing and separate hash/data storage</li> <li>Routing Layer: Demultiplexer managing multiple storage backends with different policies</li> <li>Storage Backends: Local filesystem, S3-compatible storage, and Solana blockchain storage</li> <li>Layer Relationships: How layers reference and chain to each other</li> </ul> <p>Key Configuration Concepts:</p> <ul> <li>Each layer has a unique name (e.g., <code>local_layer</code>, <code>solana_layer</code>) used for referencing</li> <li>The <code>root</code> parameter defines the entry point layer</li> <li>Layers can reference other layers to create processing chains</li> <li>The <code>demultiplexer</code> layer enables parallel operations across multiple backends</li> <li>Each layer type has specific configuration parameters (see individual layer documentation)</li> </ul> <p>For detailed configuration options for each layer type, see the layer documentation.</p>"},{"location":"index.html#run-an-example","title":"Run an Example","text":"<p>After learning how to create a config, it's time run one example.</p> <p>The FUSE example is the one that supports the most features in this repo. It's the one you should build to better test our layers and features. For more info on how to run the other examples, please visit its dedicated info pages.</p> <pre><code># Build and run the FUSE example\nmake examples/fuse/build\nmake examples/fuse/run\n</code></pre>"},{"location":"index.html#available-commands","title":"Available Commands","text":"<pre><code>make help                    # Show all available targets\n</code></pre>"},{"location":"index.html#contribute-adding-a-new-layer","title":"Contribute: Adding a New Layer","text":"<p>To add a new layer to the library:</p> <ol> <li>Create layer files: <code>layers/your_layer/your_layer.c</code>, <code>your_layer.h</code>, <code>config.h</code></li> <li>Add to enum: Add <code>LAYER_YOUR_LAYER</code> to <code>shared/enums/layer_type.h</code></li> <li>Update config system: Add your layer to <code>config/declarations.h</code>, <code>parser.c</code>, and <code>builder.c</code></li> <li>Implement functions: Create <code>your_layer_init()</code> and implement all POSIX operations</li> <li>Add to Makefile: Include your layer in the build system</li> </ol> <p>See existing layers like <code>compression</code> or <code>local</code> for reference implementations.</p>"},{"location":"index.html#documentation-system","title":"Documentation System","text":"<p>This project uses MkDocs with Material theme for generating searchable documentation from README files.</p>"},{"location":"index.html#docs","title":"Docs","text":""},{"location":"index.html#documentation-commands","title":"Documentation Commands","text":"<pre><code>make docs/serve     # Start development server with live reload\nmake docs/build     # Generate static HTML documentation  \nmake docs/clean     # Clean generated documentation files\nmake docs/links     # Manually create/update symbolic links\n</code></pre>"},{"location":"index.html#how-it-works","title":"How It Works","text":"<ul> <li>Automatic Discovery: The system automatically finds all <code>.md</code> files in the repository</li> <li>Dynamic Linking: Creates symbolic links in <code>docs/mkdocs/</code> pointing to actual markdown files</li> <li>Preserves Structure: Original markdown files stay in their natural locations for GitHub navigation</li> <li>Clean Separation: Generated files go to <code>docs/mkdocs_static/</code>, original docs resources remain untouched</li> <li>Auto-Updates: GitHub Action automatically rebuilds documentation when any <code>.md</code> file changes</li> </ul>"},{"location":"index.html#markdown-file-discovery","title":"Markdown File Discovery","text":"<p>Any <code>.md</code> file in the repository will be automatically included in the documentation.</p> <p>Included Files: All <code>.md</code> files except those in excluded directories (<code>build/</code>, <code>lib/</code>, etc.) or common non-documentation files (<code>CHANGELOG.md</code>, <code>CONTRIBUTING.md</code>, <code>LICENSE.md</code>).</p> <p>Structure Preservation: The exact original file structure and names are preserved:</p> <ul> <li><code>layers/local/README.md</code> \u2192 <code>layers/local/README.md</code></li> <li><code>config/INSTALL.md</code> \u2192 <code>config/INSTALL.md</code></li> <li>Root <code>README.md</code> \u2192 <code>index.md</code> (MkDocs homepage convention)</li> </ul> <p>Link Compatibility: Use full paths (e.g., <code>layers/local/README.md</code>) for links that work in both GitHub and MkDocs.</p>"},{"location":"index.html#generated-structure","title":"Generated Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 mkdocs/           # Source links (auto-generated, don't edit)\n\u251c\u2500\u2500 mkdocs_static/    # Static HTML output (for deployment)\n\u251c\u2500\u2500 *.pdf *.png       # Original documentation resources (preserved)\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"index.html#viewing-documentation","title":"Viewing Documentation","text":"<ul> <li>Development: Run <code>make docs/serve</code> and visit http://localhost:8000</li> <li>Static: Open <code>docs/mkdocs_static/index.html</code> in your browser</li> <li>GitHub: Navigate README files naturally in their directories</li> </ul>"},{"location":"index.html#license","title":"License","text":"<p>This project is licensed under the terms specified in the LICENSE file.</p> <p>Need help? Check the documentation links above or run <code>make help</code> for available commands.</p>"},{"location":"config/index.html","title":"Configuration System","text":"<p>The Modular IO Library uses a TOML-based configuration system that allows you to define layer architectures and configure system behavior.</p>"},{"location":"config/index.html#overview","title":"Overview","text":"<p>The configuration system enables you to:</p> <ul> <li>Define layer hierarchies and relationships</li> <li>Configure individual layer parameters</li> <li>Set up logging levels and destinations</li> <li>Create multi-backend storage architectures</li> </ul>"},{"location":"config/index.html#configuration-files","title":"Configuration Files","text":""},{"location":"config/index.html#primary-configuration","title":"Primary Configuration","text":"<ul> <li><code>config.toml</code> - Main configuration file (copy from <code>config.toml.example</code>)</li> <li><code>zlog.conf</code> - Logging destinations and formats</li> </ul>"},{"location":"config/index.html#toml-configuration-structure","title":"TOML Configuration Structure","text":""},{"location":"config/index.html#basic-structure","title":"Basic Structure","text":"<pre><code>root = \"layer_name\"           # Entry point layer\nlog_mode = \"info\"            # Global logging level\n\n[layer_name]\ntype = \"layer_type\"          # Layer implementation\n# layer-specific parameters...\n</code></pre>"},{"location":"config/index.html#supported-layer-types","title":"Supported Layer Types","text":"<ul> <li><code>local</code> - Local filesystem storage</li> <li><code>remote</code> - Network-based remote storage  </li> <li><code>anti_tampering</code> - Data integrity verification</li> <li><code>compression</code> - Data compression (LZ4/ZSTD)</li> <li><code>block_align</code> - Block-aligned I/O operations</li> <li><code>demultiplexer</code> - Parallel multi-backend operations</li> <li><code>invisible_storage</code> - Invisible storage integration</li> </ul>"},{"location":"config/index.html#configuration-patterns","title":"Configuration Patterns","text":""},{"location":"config/index.html#simple-configurations","title":"Simple Configurations","text":"<p>Basic single-layer setups for straightforward use cases.</p>"},{"location":"config/index.html#layered-architectures","title":"Layered Architectures","text":"<p>Multi-layer configurations that combine different functionalities:</p> <ul> <li>Data integrity layers with storage backends</li> <li>Compression layers with multiple storage targets</li> <li>Block alignment with various storage types</li> </ul>"},{"location":"config/index.html#multi-backend-setups","title":"Multi-Backend Setups","text":"<p>Complex configurations using the demultiplexer layer:</p> <ul> <li>Parallel writes to multiple storage systems</li> <li>Enforced vs optional storage backends</li> <li>Read/write passthrough configurations</li> </ul>"},{"location":"config/index.html#logging-configuration","title":"Logging Configuration","text":""},{"location":"config/index.html#toml-log-levels","title":"TOML Log Levels","text":"<p>Configure logging in your <code>config.toml</code>:</p> <pre><code>log_mode = \"debug\"  # Options: disabled, screen, error, warn, info, debug\n</code></pre> <p>Log Level Hierarchy (each level includes higher priority levels):</p> <ul> <li><code>disabled</code>: No logging output</li> <li><code>screen</code>: Terminal/console output only</li> <li><code>error</code>: Error conditions + screen output  </li> <li><code>warn</code>: Warning messages + error + screen output</li> <li><code>info</code>: General information + warn + error + screen output</li> <li><code>debug</code>: Detailed diagnostics + info + warn + error + screen output</li> </ul>"},{"location":"config/index.html#zlog-configuration-zlogconf","title":"ZLog Configuration (<code>zlog.conf</code>)","text":"<p>Configure output destinations and formats:</p> <pre><code>[global]\nfile perms = 0666\n\n[formats]  \nsimple=\"[%d] - %m%n\"\n\n[rules]\nmodular_lib.DEBUG     \"%E(PWD)/logs/debug.log\"; simple\nmodular_lib.INFO      \"%E(PWD)/logs/info.log\"; simple\nmodular_lib.WARN      \"%E(PWD)/logs/warn.log\"; simple\nmodular_lib.ERROR     \"%E(PWD)/logs/error.log\"; simple\nmodular_lib.*         &gt;stdout; simple\n</code></pre> <p>Environment Variables: Use <code>%E(VAR_NAME)</code> for dynamic paths</p> <ul> <li><code>%E(PWD)</code> - Current working directory</li> <li><code>%E(HOME)</code> - User home directory</li> </ul>"},{"location":"config/index.html#log-output","title":"Log Output","text":"<p>Generated log files:</p> <ul> <li><code>logs/debug.log</code> - Debug level and above</li> <li><code>logs/error.log</code> - Error level only  </li> <li><code>logs/info.log</code> - Info level and above</li> <li><code>logs/warn.log</code> - Warning level and above</li> <li>Console output - All enabled levels</li> </ul>"},{"location":"config/index.html#configuration-validation","title":"Configuration Validation","text":"<p>The system validates configurations at startup:</p> <ul> <li>Layer dependencies - Referenced layers must exist</li> <li>Type compatibility - Layer types must be implemented</li> <li>Parameter validation - Required parameters must be provided</li> <li>Circular references - Prevents infinite layer loops</li> </ul>"},{"location":"config/index.html#best-practices","title":"Best Practices","text":""},{"location":"config/index.html#configuration-design","title":"Configuration Design","text":"<ul> <li>Start Simple - Begin with basic configurations and add complexity</li> <li>Use Descriptive Names - Layer names should reflect their purpose</li> <li>Document Configurations - Comment complex setups</li> <li>Version Control - Keep configuration files in version control</li> </ul>"},{"location":"config/index.html#testing-and-deployment","title":"Testing and Deployment","text":"<ul> <li>Test Configurations - Validate with simple operations before production</li> <li>Backup Configurations - Keep copies of working configurations</li> <li>Environment-specific - Use different configs for dev/staging/production</li> <li>Monitor Logs - Check log output after configuration changes</li> </ul>"},{"location":"config/index.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"config/index.html#common-issues","title":"Common Issues","text":"<ul> <li>Missing layer reference: Check layer names match exactly</li> <li>Invalid layer type: Verify layer type is implemented</li> <li>Permission errors: Check file paths and permissions</li> <li>Logging not working: Verify <code>zlog.conf</code> paths exist</li> </ul>"},{"location":"config/index.html#debug-strategies","title":"Debug Strategies","text":"<ul> <li>Set <code>log_mode = \"debug\"</code> for verbose output</li> <li>Check log files for detailed error messages</li> <li>Validate TOML syntax with online validators</li> <li>Test with minimal configurations first</li> <li>Use layer-specific documentation for parameter details </li> </ul>"},{"location":"examples/fuse/index.html","title":"FUSE Example","text":"<p>The FUSE example demonstrates the Modular IO Library in a real-world filesystem context. It implements a FUSE-based passthrough filesystem that uses the layer system for all file operations.</p>"},{"location":"examples/fuse/index.html#overview","title":"Overview","text":"<p>The FUSE example provides:</p> <ul> <li>FUSE filesystem implementation using the Modular IO Library</li> <li>Passthrough functionality that mirrors a backend directory</li> <li>Layer integration showing real-world usage patterns</li> <li>Automatic directory management with mount point and backend creation</li> <li>Production-ready code demonstrating best practices</li> </ul>"},{"location":"examples/fuse/index.html#features","title":"Features","text":"<ul> <li>Full FUSE Implementation: Complete filesystem interface</li> <li>Layer System Integration: Uses configured layer stack for all operations</li> <li>Automatic Setup: Creates necessary directories automatically</li> <li>Background/Foreground Modes: Supports both daemon and foreground operation</li> <li>Signal Handling: Proper cleanup and unmounting on signals</li> <li>Error Handling: Comprehensive error handling and logging</li> </ul>"},{"location":"examples/fuse/index.html#architecture","title":"Architecture","text":""},{"location":"examples/fuse/index.html#integration-model","title":"Integration Model","text":"<p>The FUSE example acts as a bridge between the FUSE kernel interface and the Modular IO Library:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   File System   \u2502 (User applications)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 FUSE Kernel     \u2502 (Linux FUSE kernel module)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 FUSE Example    \u2502 (Our implementation)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Modular IO Lib  \u2502 (Configured layer stack)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Backend Storage \u2502 (examples/fuse/backend_data/)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"examples/fuse/index.html#directory-structure","title":"Directory Structure","text":"<pre><code>examples/fuse/\n\u251c\u2500\u2500 Makefile                    # Build configuration\n\u251c\u2500\u2500 passthrough.c              # Main FUSE implementation\n\u251c\u2500\u2500 passthrough_helpers.h      # Helper functions and utilities\n\u251c\u2500\u2500 mount_point/               # FUSE mount point (auto-created)\n\u2514\u2500\u2500 backend_data/              # Backend storage directory (auto-created)\n</code></pre>"},{"location":"examples/fuse/index.html#building-and-running","title":"Building and Running","text":""},{"location":"examples/fuse/index.html#build","title":"Build","text":"<pre><code># Build the FUSE example\nmake examples/fuse/build\n</code></pre>"},{"location":"examples/fuse/index.html#run-options","title":"Run Options","text":"<pre><code># Foreground mode (for debugging)\nmake examples/fuse/run\n\n# Background mode (daemon)\nmake examples/fuse/run/daemon\n\n# Stop the filesystem\nmake examples/fuse/stop\n</code></pre>"},{"location":"examples/fuse/index.html#configuration-file","title":"Configuration File","text":"<p>By default, the FUSE example uses <code>./config.toml</code> in the project root directory. You can specify a custom configuration file using the <code>MODULAR_IO_CONFIG_PATH</code> variable:</p> <pre><code># Use custom config file (absolute path)\nmake examples/fuse/run MODULAR_IO_CONFIG_PATH=/path/to/my/config.toml\n\n# Use custom config file (relative to project root)\nmake examples/fuse/run MODULAR_IO_CONFIG_PATH=configs/production.toml\n\n# Set via environment variable\nexport MODULAR_IO_CONFIG_PATH=/path/to/config.toml\nmake examples/fuse/run\n\n# Or inline\nMODULAR_IO_CONFIG_PATH=/path/to/config.toml make examples/fuse/run\n</code></pre> <p>Note: Relative paths are automatically resolved relative to the project root directory (<code>ROOT_DIR</code>).</p>"},{"location":"examples/fuse/index.html#clean","title":"Clean","text":"<pre><code># Clean build artifacts\nmake examples/fuse/clean\n</code></pre>"},{"location":"examples/fuse/index.html#usage","title":"Usage","text":"<p>Once running, the FUSE filesystem appears as a normal directory that can be accessed by any application. All file operations are transparently processed through the configured layer stack.</p>"},{"location":"examples/fuse/index.html#basic-operations","title":"Basic Operations","text":"<p>Standard filesystem operations are supported:</p> <ul> <li>File operations: Create, read, write, delete files</li> <li>Directory operations: Create, list, remove directories</li> <li>Metadata operations: Get/set file attributes and permissions</li> <li>Large file support: Handle files of arbitrary size</li> </ul>"},{"location":"examples/fuse/index.html#layer-configuration","title":"Layer Configuration","text":"<p>The filesystem behavior can be modified by changing the layer configuration:</p> <ul> <li>Compression: Automatically compress stored data</li> <li>Integrity: Add hash-based verification</li> <li>Multi-backend: Replicate data across multiple storage systems</li> <li>Block alignment: Optimize for specific storage characteristics</li> </ul>"},{"location":"examples/fuse/index.html#implementation-details","title":"Implementation Details","text":""},{"location":"examples/fuse/index.html#fuse-operations","title":"FUSE Operations","text":"<p>The implementation provides standard FUSE operations:</p> <ul> <li>File I/O: Read, write operations with offset support</li> <li>Metadata: File attributes, permissions, timestamps</li> <li>Directory management: Directory creation, listing, removal</li> <li>Path resolution: Proper path handling and resolution</li> </ul>"},{"location":"examples/fuse/index.html#error-handling","title":"Error Handling","text":"<p>Comprehensive error handling with appropriate FUSE error codes:</p> <ul> <li>File system errors: ENOENT, EACCES, EIO, ENOSPC</li> <li>Layer propagation: Errors from underlying layers are properly translated</li> <li>Resource management: Proper cleanup on errors and shutdown</li> </ul>"},{"location":"examples/fuse/index.html#performance-considerations","title":"Performance Considerations","text":"<p>Design choices for optimal performance:</p> <ul> <li>Direct passthrough: Minimal overhead for supported operations</li> <li>Buffer management: Efficient memory usage for large files</li> <li>Concurrent access: Thread-safe operation handling</li> </ul>"},{"location":"examples/fuse/index.html#testing","title":"Testing","text":""},{"location":"examples/fuse/index.html#functionality-testing","title":"Functionality Testing","text":"<p>Test basic filesystem operations:</p> <ul> <li>File creation, reading, writing, deletion</li> <li>Directory operations and navigation</li> <li>Large file handling</li> <li>Permission and attribute management</li> </ul>"},{"location":"examples/fuse/index.html#integration-testing","title":"Integration Testing","text":"<p>Verify layer integration:</p> <ul> <li>Test different layer configurations</li> <li>Verify data integrity through layers</li> <li>Performance testing with various layer stacks</li> </ul>"},{"location":"examples/fuse/index.html#error-scenarios","title":"Error Scenarios","text":"<p>Test error handling:</p> <ul> <li>Invalid file operations</li> <li>Permission denied scenarios</li> <li>Layer failure conditions</li> <li>Resource exhaustion situations</li> </ul>"},{"location":"examples/fuse/index.html#requirements","title":"Requirements","text":""},{"location":"examples/fuse/index.html#system-dependencies","title":"System Dependencies","text":"<ul> <li>FUSE: libfuse3-dev or equivalent</li> <li>Build tools: Standard C development environment</li> <li>Permissions: User must have FUSE access rights</li> </ul>"},{"location":"examples/fuse/index.html#configuration","title":"Configuration","text":"<ul> <li>Valid <code>config.toml</code> with layer configuration</li> <li>Proper logging setup via <code>zlog.conf</code></li> <li>Sufficient permissions for mount operations</li> </ul>"},{"location":"examples/fuse/index.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/fuse/index.html#common-issues","title":"Common Issues","text":"<p>FUSE Not Available:</p> <ul> <li>Verify FUSE is installed on the system</li> <li>Check if FUSE kernel module is loaded</li> <li>Install development headers if building from source</li> </ul> <p>Permission Issues:</p> <ul> <li>Add user to the <code>fuse</code> group</li> <li>Check mount point permissions</li> <li>Verify backend directory access</li> </ul> <p>Mount Failures:</p> <ul> <li>Ensure mount point directory exists and is empty</li> <li>Check for conflicting mount points</li> <li>Verify configuration file syntax</li> </ul> <p>Layer Configuration Issues:</p> <ul> <li>Validate TOML configuration syntax</li> <li>Check layer parameter correctness</li> <li>Verify required dependencies are built</li> </ul>"},{"location":"examples/fuse/index.html#debugging","title":"Debugging","text":"<ul> <li>Foreground mode: Run with <code>make examples/fuse/run</code> for detailed output</li> <li>Log analysis: Check generated log files for error details</li> <li>FUSE debugging: Use FUSE debugging options for low-level issues</li> <li>Layer debugging: Enable debug logging in configuration </li> </ul>"},{"location":"examples/invisible/index.html","title":"Invisible Example","text":"<p>This directory contains an example, named Invisible, that demonstrates how to interact with the Invisible Storage C bindings.</p>"},{"location":"examples/invisible/index.html#overview","title":"Overview","text":"<p>The <code>Invisible</code> example showcases how to:</p> <ul> <li>Interact with S3 via OpenDAL</li> <li>Interact with the Solana blockchain using the Solana SDK</li> </ul>"},{"location":"examples/invisible/index.html#files-included","title":"Files Included","text":"<ul> <li><code>invisible.c</code> \u2013 Main source file with logic for interacting with Invisible Storage</li> <li><code>invisible.h</code> \u2013 Header file</li> <li><code>Makefile</code> \u2013 Automates the setup process, including:</li> <li>Cloning the Invisible Storage C bindings repository (release 0.0.1).</li> <li>Compiling the example and linking against the necessary libraries for S3 and Solana operations.</li> </ul>"},{"location":"examples/invisible/index.html#requirements","title":"Requirements","text":"<ul> <li>Rust</li> <li>Configure a Solana devnet using Solana CLI</li> <li>Configure an S3 bucket</li> </ul>"},{"location":"examples/invisible/index.html#configuration","title":"Configuration","text":"<ul> <li>follow the config instructions provided in the Invisible Storage repository.</li> </ul>"},{"location":"examples/invisible/index.html#running-the-example","title":"Running the Example","text":"<pre><code>make\n./invisible\n</code></pre>"},{"location":"examples/storserver/index.html","title":"Storage Server Example","text":"<p>The storage server example provides a network-based storage server that works with the remote layer of the Modular IO Library. It implements a TCP server that handles remote file operations, enabling distributed storage scenarios and client-server architectures.</p>"},{"location":"examples/storserver/index.html#overview","title":"Overview","text":"<p>The storage server example offers: - Network storage server for remote file operations - TCP-based protocol for client-server communication - Multi-client support with concurrent connection handling - Standard file operations over network - Independent operation from the layer system (server-side implementation)</p>"},{"location":"examples/storserver/index.html#features","title":"Features","text":"<ul> <li>TCP Server: Listens for client connections on configurable port</li> <li>Multi-client: Handles multiple concurrent client connections</li> <li>Full File Operations: Supports read, write, open, close, stat operations</li> <li>Binary Protocol: Efficient binary message protocol</li> <li>Error Handling: Proper error propagation to clients</li> <li>Logging: Comprehensive operation logging</li> </ul>"},{"location":"examples/storserver/index.html#architecture","title":"Architecture","text":""},{"location":"examples/storserver/index.html#server-client-model","title":"Server-Client Model","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    TCP/IP    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Clients       \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502 Storage Server  \u2502\n\u2502 (Remote Layer)  \u2502   Protocol   \u2502   (storserver)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                          \u2502\n                                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                 \u2502 Local Storage   \u2502\n                                 \u2502   (Server-side) \u2502\n                                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"examples/storserver/index.html#protocol-implementation","title":"Protocol Implementation","text":"<p>The server uses the same message protocol as the remote layer:</p> <pre><code>typedef struct msg {\n    int op;                    // Operation type\n    char path[PSIZE];         // File path\n    char buffer[BSIZE];       // Data buffer\n    int flags;                // Open flags  \n    off_t offset;             // File offset\n    size_t size;              // Operation size\n    ssize_t res;              // Result code\n    int fd;                   // File descriptor\n    mode_t mode;              // File permissions\n    struct stat st;           // File status\n} MSG;\n</code></pre>"},{"location":"examples/storserver/index.html#supported-operations","title":"Supported Operations","text":"<ul> <li>READ (0): Read data from file</li> <li>WRITE (1): Write data to file</li> <li>STAT (2): Get file status information</li> <li>OPEN (3): Open file with specified flags</li> <li>UNLINK (4): Delete file</li> <li>CLOSE (5): Close file descriptor</li> </ul>"},{"location":"examples/storserver/index.html#building-and-running","title":"Building and Running","text":""},{"location":"examples/storserver/index.html#build-the-server","title":"Build the Server","text":"<pre><code># Build the storage server example\nmake examples/storserver/build\n</code></pre>"},{"location":"examples/storserver/index.html#run-the-server","title":"Run the Server","text":"<pre><code># Run the storage server\nmake examples/storserver/run\n</code></pre>"},{"location":"examples/storserver/index.html#clean-build-artifacts","title":"Clean Build Artifacts","text":"<pre><code># Clean the storage server example\nmake examples/storserver/clean\n</code></pre>"},{"location":"examples/storserver/index.html#server-configuration","title":"Server Configuration","text":""},{"location":"examples/storserver/index.html#default-configuration","title":"Default Configuration","text":"<p>The server uses hardcoded configuration (defined in <code>remote.h</code>): <pre><code>#define PORT 5000          // Server port\n#define IP \"127.0.0.1\"     // Server bind address\n#define LISTEN_BACKLOG 50  // Connection queue size\n</code></pre></p>"},{"location":"examples/storserver/index.html#buffer-sizes","title":"Buffer Sizes","text":"<pre><code>#define BSIZE 4096    // Data buffer size\n#define PSIZE 512     // Path string size\n</code></pre>"},{"location":"examples/storserver/index.html#usage-examples","title":"Usage Examples","text":""},{"location":"examples/storserver/index.html#basic-server-operation","title":"Basic Server Operation","text":"<pre><code># Terminal 1: Start the server\nmake examples/storserver/run\n\n# Terminal 2: Test with a client using remote layer\n# Configure config.toml with remote layer\nroot = \"remote_storage\"\n[remote_storage]\ntype = \"remote\"\n\n# Run application that uses remote layer\n./your_application\n</code></pre>"},{"location":"examples/storserver/index.html#multi-client-testing","title":"Multi-Client Testing","text":"<pre><code># Start server\nmake examples/storserver/run &amp;\n\n# Multiple clients can connect simultaneously\n# Each client gets independent file operations\n</code></pre>"},{"location":"examples/storserver/index.html#integration-with-examples","title":"Integration with Examples","text":"<pre><code># Start storage server\nmake examples/storserver/run &amp;\n\n# Use FUSE example with remote backend\n# Configure FUSE to use remote layer\n# Files written to FUSE will be stored on server\n</code></pre>"},{"location":"examples/storserver/index.html#implementation-details","title":"Implementation Details","text":""},{"location":"examples/storserver/index.html#server-initialization","title":"Server Initialization","text":"<pre><code>int main() {\n    // Create socket\n    int server_socket = socket(AF_INET, SOCK_STREAM, 0);\n\n    // Bind to address and port\n    struct sockaddr_in server_addr = {\n        .sin_family = AF_INET,\n        .sin_addr.s_addr = inet_addr(IP),\n        .sin_port = htons(PORT)\n    };\n    bind(server_socket, (struct sockaddr*)&amp;server_addr, sizeof(server_addr));\n\n    // Listen for connections\n    listen(server_socket, LISTEN_BACKLOG);\n\n    // Accept and handle client connections\n    while (1) {\n        int client_socket = accept(server_socket, NULL, NULL);\n        handle_client(client_socket);\n    }\n}\n</code></pre>"},{"location":"examples/storserver/index.html#client-handler","title":"Client Handler","text":"<p>Each client connection is handled by processing messages:</p> <pre><code>void handle_client(int client_socket) {\n    MSG msg;\n\n    while (1) {\n        // Receive message from client\n        if (recv(client_socket, &amp;msg, sizeof(MSG), 0) &lt;= 0) {\n            break;  // Client disconnected\n        }\n\n        // Process operation\n        switch (msg.op) {\n            case READ:\n                handle_read(&amp;msg);\n                break;\n            case WRITE:\n                handle_write(&amp;msg);\n                break;\n            case OPEN:\n                handle_open(&amp;msg);\n                break;\n            // ... other operations\n        }\n\n        // Send response back to client\n        send(client_socket, &amp;msg, sizeof(MSG), 0);\n    }\n\n    close(client_socket);\n}\n</code></pre>"},{"location":"examples/storserver/index.html#file-operation-handlers","title":"File Operation Handlers","text":""},{"location":"examples/storserver/index.html#read-operation","title":"Read Operation","text":"<pre><code>void handle_read(MSG *msg) {\n    ssize_t bytes_read = pread(msg-&gt;fd, msg-&gt;buffer, msg-&gt;size, msg-&gt;offset);\n    msg-&gt;res = bytes_read;\n}\n</code></pre>"},{"location":"examples/storserver/index.html#write-operation","title":"Write Operation","text":"<pre><code>void handle_write(MSG *msg) {\n    ssize_t bytes_written = pwrite(msg-&gt;fd, msg-&gt;buffer, msg-&gt;size, msg-&gt;offset);\n    msg-&gt;res = bytes_written;\n}\n</code></pre>"},{"location":"examples/storserver/index.html#open-operation","title":"Open Operation","text":"<pre><code>void handle_open(MSG *msg) {\n    int fd = open(msg-&gt;path, msg-&gt;flags, msg-&gt;mode);\n    msg-&gt;res = fd;\n}\n</code></pre>"},{"location":"examples/storserver/index.html#protocol-details","title":"Protocol Details","text":""},{"location":"examples/storserver/index.html#message-flow","title":"Message Flow","text":"<ol> <li>Client Request: Client sends MSG structure with operation details</li> <li>Server Processing: Server processes the requested operation</li> <li>Server Response: Server sends modified MSG back with results</li> <li>Error Handling: Errors communicated via negative result codes</li> </ol>"},{"location":"examples/storserver/index.html#connection-management","title":"Connection Management","text":"<ul> <li>Persistent Connections: Clients maintain connections across operations</li> <li>Connection Pooling: Multiple clients can connect simultaneously</li> <li>Cleanup: Server handles client disconnections gracefully</li> </ul>"},{"location":"examples/storserver/index.html#data-transfer","title":"Data Transfer","text":"<ul> <li>Binary Protocol: Efficient binary message format</li> <li>Fixed Buffer Size: BSIZE limits single operation data transfer</li> <li>Large Files: Large files handled via multiple operations</li> </ul>"},{"location":"examples/storserver/index.html#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"examples/storserver/index.html#throughput","title":"Throughput","text":"<ul> <li>Network Limited: Performance limited by network bandwidth</li> <li>Concurrent Clients: Server handles multiple clients concurrently</li> <li>Local I/O: Server-side I/O performance affects overall throughput</li> </ul>"},{"location":"examples/storserver/index.html#scalability","title":"Scalability","text":"<ul> <li>Connection Limits: Limited by system file descriptor limits</li> <li>Memory Usage: Each client connection uses memory for buffers</li> <li>CPU Usage: Minimal CPU overhead per operation</li> </ul>"},{"location":"examples/storserver/index.html#optimization-opportunities","title":"Optimization Opportunities","text":"<ul> <li>Threading: Multi-threaded client handling</li> <li>Async I/O: Non-blocking I/O operations</li> <li>Connection Pooling: Reuse connections efficiently</li> <li>Caching: Server-side caching for frequently accessed files</li> </ul>"},{"location":"examples/storserver/index.html#security-considerations","title":"Security Considerations","text":""},{"location":"examples/storserver/index.html#current-limitations","title":"Current Limitations","text":"<ul> <li>No Authentication: Server accepts all connections</li> <li>No Encryption: Data transmitted in plaintext</li> <li>No Authorization: No access control on files</li> <li>Trust Model: Assumes trusted clients and network</li> </ul>"},{"location":"examples/storserver/index.html#security-recommendations","title":"Security Recommendations","text":"<ul> <li>Network Security: Use in trusted network environments</li> <li>Firewall Rules: Restrict access to server port</li> <li>VPN/Tunneling: Use secure tunneling for untrusted networks</li> <li>Access Control: Implement file system permissions</li> </ul>"},{"location":"examples/storserver/index.html#future-security-enhancements","title":"Future Security Enhancements","text":"<ul> <li>Authentication: Client certificate or token-based auth</li> <li>Encryption: TLS/SSL encryption for data transmission</li> <li>Authorization: Per-client access control lists</li> <li>Audit Logging: Detailed operation audit logs</li> </ul>"},{"location":"examples/storserver/index.html#testing","title":"Testing","text":""},{"location":"examples/storserver/index.html#unit-testing","title":"Unit Testing","text":"<pre><code># Test server functionality\nmake examples/storserver/build\nmake tests/run  # Includes server integration tests\n</code></pre>"},{"location":"examples/storserver/index.html#integration-testing","title":"Integration Testing","text":"<pre><code># Start server\nmake examples/storserver/run &amp;\nSERVER_PID=$!\n\n# Test with remote layer\nroot = \"remote_test\"\n[remote_test]\ntype = \"remote\"\n\n# Run client operations\n./test_client\n\n# Cleanup\nkill $SERVER_PID\n</code></pre>"},{"location":"examples/storserver/index.html#load-testing","title":"Load Testing","text":"<pre><code># Start server\nmake examples/storserver/run &amp;\n\n# Multiple concurrent clients\nfor i in {1..10}; do\n    ./test_client &amp;\ndone\nwait\n\n# Monitor server performance\ntop -p $(pgrep storserver)\n</code></pre>"},{"location":"examples/storserver/index.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/storserver/index.html#common-issues","title":"Common Issues","text":""},{"location":"examples/storserver/index.html#server-wont-start","title":"Server Won't Start","text":"<pre><code># Check if port is already in use\nnetstat -ln | grep :5000\n\n# Kill existing process using port\nsudo lsof -ti:5000 | xargs kill -9\n\n# Check firewall settings\nsudo iptables -L | grep 5000\n</code></pre>"},{"location":"examples/storserver/index.html#connection-refused","title":"Connection Refused","text":"<pre><code># Verify server is running\nnetstat -ln | grep :5000\n\n# Test connection\ntelnet 127.0.0.1 5000\n\n# Check client configuration\n# Ensure remote layer configured correctly\n</code></pre>"},{"location":"examples/storserver/index.html#performance-issues","title":"Performance Issues","text":"<pre><code># Monitor network usage\niftop\n\n# Monitor server resources\nhtop\n\n# Check for connection limits\nulimit -n\n</code></pre>"},{"location":"examples/storserver/index.html#debugging","title":"Debugging","text":""},{"location":"examples/storserver/index.html#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code>// Add debug prints to server code\nprintf(\"Handling client: %d\\n\", client_socket);\nprintf(\"Operation: %d, Path: %s\\n\", msg.op, msg.path);\n</code></pre>"},{"location":"examples/storserver/index.html#network-debugging","title":"Network Debugging","text":"<pre><code># Capture network traffic\nsudo tcpdump -i lo port 5000\n\n# Monitor server connections\nss -tuln | grep :5000\n</code></pre>"},{"location":"examples/storserver/index.html#file-system-debugging","title":"File System Debugging","text":"<pre><code># Monitor server-side file operations\nstrace -p $(pgrep storserver)\n\n# Check file permissions\nls -la /path/to/server/files\n</code></pre>"},{"location":"examples/storserver/index.html#real-world-applications","title":"Real-World Applications","text":""},{"location":"examples/storserver/index.html#use-cases","title":"Use Cases","text":"<ol> <li>Distributed Storage: Centralized file storage for multiple clients</li> <li>Backup Systems: Remote backup destination</li> <li>Development/Testing: Test remote layer functionality</li> <li>Microservices: File storage service in microservice architecture</li> <li>Edge Computing: Remote file access in edge scenarios</li> </ol>"},{"location":"examples/storserver/index.html#production-deployment","title":"Production Deployment","text":"<ul> <li>Process Management: Use systemd or similar for service management</li> <li>Load Balancing: Multiple server instances with load balancer</li> <li>Monitoring: Health checks and performance monitoring</li> <li>Backup: Regular backup of server-side storage</li> </ul>"},{"location":"examples/storserver/index.html#future-enhancements","title":"Future Enhancements","text":""},{"location":"examples/storserver/index.html#planned-features","title":"Planned Features","text":"<ul> <li>Configuration File: TOML-based server configuration</li> <li>Authentication: Client authentication mechanisms</li> <li>SSL/TLS: Encrypted communication</li> <li>Clustering: Multi-server clustering support</li> <li>Statistics: Operation statistics and monitoring</li> </ul>"},{"location":"examples/storserver/index.html#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Future server configuration\n[server]\nbind_address = \"0.0.0.0\"\nport = 5000\nmax_clients = 100\nbuffer_size = 8192\nssl_enabled = true\nssl_cert = \"/path/to/cert.pem\"\nssl_key = \"/path/to/key.pem\"\n\n[auth]\nenabled = true\nmethod = \"token\"\ntoken_file = \"/path/to/tokens\"\n\n[storage]\nroot_directory = \"/var/lib/storserver\"\nmax_file_size = \"1GB\"\ntemp_directory = \"/tmp/storserver\"\n</code></pre>"},{"location":"examples/storserver/index.html#integration-with-layer-system","title":"Integration with Layer System","text":"<p>While the storage server operates independently, it integrates with the layer system through the remote layer:</p>"},{"location":"examples/storserver/index.html#client-side-integration","title":"Client-Side Integration","text":"<pre><code># Client configuration using remote layer\nroot = \"remote_with_integrity\"\n\n[remote_with_integrity]\ntype = \"anti_tampering\"\ndata_layer = \"remote_storage\"\nhash_layer = \"local_hashes\"\n\n[remote_storage]\ntype = \"remote\"\n\n[local_hashes]\ntype = \"local\"\n</code></pre> <p>This configuration provides: - Remote storage via the storage server - Local integrity checking with anti-tampering layer - Transparent operation for applications </p>"},{"location":"layers/anti_tampering/index.html","title":"Anti-Tampering Layer","text":"<p>The anti-tampering layer provides comprehensive data integrity verification using configurable hash algorithms with thread-safe file locking to prevent race conditions. It ensures data anti-tampering by automatically computing and verifying file hashes on file closes.</p>"},{"location":"layers/anti_tampering/index.html#key-features","title":"Key Features","text":"<ul> <li>Configurable Hash Algorithms: Supports SHA-256 and SHA-512 with runtime selection</li> <li>Automatic Hash Operations: Computes hashes on file close, verifies on file open</li> <li>Atomic Operations: All operations are atomic with proper locking</li> <li>Concurrent Reader Support: Multiple readers with exclusive writer access</li> <li>Race Condition Prevention: Comprehensive locking strategy prevents data corruption</li> <li>Layer Agnostic: Works with any underlying storage system</li> <li>Modular Design: Uses the modular hasher system for extensible algorithm support</li> </ul>"},{"location":"layers/anti_tampering/index.html#architecture","title":"Architecture","text":"<p>The anti-tampering layer uses a dual-storage approach:</p> <ul> <li>Data Storage: File content stored in the underlying data_layer</li> <li>Hash Storage: Hash metadata stored in separate hash_layer </li> <li>Hash File Naming: Hash files named using SHA-256 of file path + \".hash\"</li> </ul> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Application   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Anti-Tampering  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Hash Layer    \u2502 \u2500\u2500\u2500\u2500 Stores hash files (.hash)\n\u2502   Data Layer    \u2502 \u2500\u2500\u2500\u2500 Stores actual file data\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"layers/anti_tampering/index.html#thread-safety-locking","title":"Thread Safety &amp; Locking","text":"<p>The anti-tampering layer implements path-based locking using pthread reader-writer locks:</p> Operation Lock Type Purpose Open READ lock Hash verification can run concurrently Read READ lock Multiple readers can access simultaneously Write WRITE lock Exclusive access during data modification Close WRITE lock Exclusive access during hash computation <p>Concurrent Operations: Multiple file opens and reads can run simultaneously. Exclusive Operations: Write and close operations block all other access.</p>"},{"location":"layers/anti_tampering/index.html#configuration","title":"Configuration","text":""},{"location":"layers/anti_tampering/index.html#toml-configuration","title":"TOML Configuration","text":"<pre><code>[anti_tamper_layer]\ntype = \"anti_tampering\"\nhashes_storage = \"/path/to/hash/directory\"\nhash_layer = \"hash_layer_name\"     # Layer for storing hash files\ndata_layer = \"data_layer_name\"     # Layer for storing actual data\nalgorithm = \"sha256\"               # Hash algorithm: \"sha256\" or \"sha512\"\n</code></pre>"},{"location":"layers/anti_tampering/index.html#parameters","title":"Parameters","text":"<ul> <li><code>hashes_storage</code> (string): Directory path prefix for hash files</li> <li><code>hash_layer</code> (string): Name of layer configuration for storing hash files</li> <li><code>data_layer</code> (string): Name of layer configuration for storing actual data</li> <li><code>algorithm</code> (string): Hash algorithm - \"sha256\" (default) or \"sha512\"</li> </ul> Algorithm Speed Security Output Size Use Case SHA256 Fast Good 64 hex chars General purpose, performance-focused SHA512 Slower Better 128 hex chars High-security requirements"},{"location":"layers/anti_tampering/index.html#end-to-end-blockchain-example","title":"End-to-End Blockchain Example","text":"<p>The following example is one you can follow along to test the anti-tampering layer with a Solana blockchain as the hash storage layer for data integrity.</p> <p>First, you need to build the project with the BUILD_INVISIBLE=1 flag to include the Solana layer:</p> <pre><code>make build BUILD_INVISIBLE=1\n</code></pre> <p>Then, you need to configure the project to use the anti-tampering layer with the Solana blockchain as the hash storage layer.</p> <p>Note: If you don't have a keypair file, you can follow the steps in the Solana Layer README to create one.</p> <pre><code>root = \"anti_tampering\"\nlog_mode = \"error\"\n\n[anti_tampering]\ntype = \"anti_tampering\"\nhashes_storage = \"/home/user/Modular-IO-Lib/examples/fuse/hashes\" # Note: Use your absolute path here #\nhash_layer = \"solana\"\ndata_layer = \"local_layer\"\nalgorithm = \"sha256\"\n\n[solana_layer]\ntype = \"solana\"\nkeypair_path = \"/home/user/.config/solana/id.json\"\nrpc_url = \"https://api.devnet.solana.com\"\n\n[local_layer]\ntype = \"local\"\n</code></pre> <p>Then run the FUSE example in one terminal from the root of the project:</p> <pre><code>make examples/fuse/run\n</code></pre> <p>Write a file into the mounted directory:</p> <pre><code>echo \"Hello, World!\" &gt; /home/user/Modular-IO-Lib/examples/fuse/mount_point/test.txt\n</code></pre> <p>Check the transactions in a solana block explorer:</p> <p>You can go to Solscan and search for your address and you should see the transaction with the hash of the file your wrote.</p> <p>Further reads of the file will compare the hash of the file with the hash stored in the Solana blockchain.</p>"},{"location":"layers/anti_tampering/index.html#operational-behavior","title":"Operational Behavior","text":""},{"location":"layers/anti_tampering/index.html#file-operations","title":"File Operations","text":"<p>Open: Verifies file integrity by comparing stored hash with computed hash Read/Write: Standard file operations with appropriate locking Close: Computes and stores file hash for future verification</p> <p>All operations are atomic and thread-safe with proper locking.</p>"},{"location":"layers/anti_tampering/index.html#hash-file-management","title":"Hash File Management","text":"<p>Hash files are named using SHA-256 of the original file path: <pre><code>Original file: /path/to/myfile.txt\nHash filename: &lt;hashes_storage&gt;/a1b2c3d4e5f6...789.hash\n</code></pre></p> <p>The hash layer can be any supported layer type (local, remote, cloud storage).</p>"},{"location":"layers/anti_tampering/index.html#error-handling","title":"Error Handling","text":""},{"location":"layers/anti_tampering/index.html#integrity-violations","title":"Integrity Violations","text":"<ul> <li>Hash Mismatch: File content doesn't match stored hash</li> <li>Missing Hash: Hash file doesn't exist for existing data file</li> <li>Corrupted Hash: Hash file is malformed or unreadable</li> </ul>"},{"location":"layers/anti_tampering/index.html#system-errors","title":"System Errors","text":"<ul> <li>Lock Failures: Unable to acquire required locks</li> <li>Storage Errors: Underlying layer errors (disk full, permissions, etc.)</li> <li>Hash Computation: Hasher algorithm failures</li> </ul>"},{"location":"layers/anti_tampering/index.html#return-codes","title":"Return Codes","text":"<ul> <li>0: Operation completed successfully</li> <li>-1: File integrity violation detected</li> <li>-2: Unable to acquire required lock</li> <li>-3: Underlying storage layer error</li> </ul>"},{"location":"layers/anti_tampering/index.html#performance","title":"Performance","text":"<p>Read Performance: Hash verification adds overhead on file open, but concurrent reads are supported Write Performance: Hash computation adds overhead on file close with exclusive access Memory Usage: O(n) for n open files, O(m) for m unique file paths</p> <p>In order to get some performance numbers, we have used the Anti-Tampering layer in the configuration while running the FUSE example on top of a PostgreSQL database. We have tested three different configurations, and also tested it agains a non-mounted directory: - Local Layer - Anti-Tampering with hashes stored on Local - Anti-Tampering with hashes stored on S3 </p> <p>We have used pgbench to benchmark our DB with three different workloads: Mixed read/write, read-only (SELECT), and write-only (INSERT). All results are reported in transactions per second (TPS).</p> <p>Test Configuration: - Platform: AWS EC2 m7i.xlarge (4 vCPUs, 16 GB RAM) - OS: AlmaLinux 9.6 (Sage Margay) - Database: PostgreSQL (v13.22) with pgbench benchmarking tool - Scale Factor: 50 - Test Duration: 5 runs of 30 minutes each</p> <p>For S3 configurations, we used a VPC Gateway Endpoint to minimize access latency.</p> Configuration Read/Write Mix Read-Only Write-Only No Fuse 3602.04 \u00b1 14.90 85943.15 \u00b1 291.07 5020.75 \u00b1 3.62 Local 3215.36 \u00b1 31.33 34709.66 \u00b1 256.66 4141.10 \u00b1 55.51 Anti-Tampering Local Hash 2159.81 \u00b1 30.52 35281.88 \u00b1 237.89 4444.91 \u00b1 357.23 Anti-Tampering S3 Hash 1790.32 \u00b1 15.17 33607.99 \u00b1 1506.85 3827.04 \u00b1 33.37"},{"location":"layers/anti_tampering/index.html#use-cases","title":"Use Cases","text":"<ul> <li>Critical data protection: Detect unauthorized modifications</li> <li>Compliance requirements: Meet data integrity standards</li> <li>Corruption detection: Identify storage-level corruption</li> <li>Tamper detection: Identify malicious file modifications</li> <li>Forensic integrity: Maintain evidence chain of custody</li> </ul>"},{"location":"layers/anti_tampering/index.html#building-and-testing","title":"Building and Testing","text":"<pre><code># Build all components\nmake build\n\n# Run tests\nmake tests/run\n</code></pre> <p>Test Coverage: Hash computation/verification, concurrent access, error handling, algorithm switching</p>"},{"location":"layers/anti_tampering/index.html#security-considerations","title":"Security Considerations","text":""},{"location":"layers/anti_tampering/index.html#hash-algorithm-security","title":"Hash Algorithm Security","text":"<ul> <li>SHA256: Cryptographically secure, widely trusted</li> <li>SHA512: More secure, recommended for sensitive data</li> <li>Collision Resistance: Both algorithms resist hash collisions</li> </ul>"},{"location":"layers/anti_tampering/index.html#protected-attack-scenarios","title":"Protected Attack Scenarios","text":"<ul> <li>File Tampering: Detects unauthorized file modifications</li> <li>Data Corruption: Identifies storage-level corruption</li> <li>Integrity Verification: Ensures data authenticity</li> </ul>"},{"location":"layers/anti_tampering/index.html#unprotected-attack-scenarios","title":"Unprotected Attack Scenarios","text":"<ul> <li>Hash File Tampering: If attacker can modify both data and hash</li> <li>Time-of-Check-Time-of-Use: Race conditions outside layer control</li> <li>Cryptographic Attacks: Algorithm-specific vulnerabilities</li> </ul>"},{"location":"layers/anti_tampering/index.html#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Store hash files on separate, secured storage</li> <li>Use SHA512 for high-security environments</li> <li>Monitor hash verification failures</li> <li>Implement backup hash storage</li> <li>Secure hash storage layer independently</li> </ul>"},{"location":"layers/anti_tampering/index.html#troubleshooting","title":"Troubleshooting","text":"<p>Common Issues: Hash mismatches, lock timeouts, permission errors, performance issues</p> <p>Debugging: Enable debug logging, check hash files, verify underlying layers, test simple operations</p> <p>Performance Tuning: Choose appropriate algorithm (SHA256 vs SHA512), optimize storage layer</p>"},{"location":"layers/anti_tampering/index.html#hasher-architecture","title":"Hasher Architecture","text":"<p>The anti-tampering layer uses a modular hasher system with: - Generic EVP Implementation: Shared OpenSSL EVP operations for all algorithms - Algorithm-Specific Wrappers: Lightweight wrappers for SHA-256 and SHA-512</p> <p>This enables easy addition of new hash algorithms while maintaining consistent interfaces. </p>"},{"location":"layers/benchmark/index.html","title":"Benchmark Layer","text":"<p>The benchmark layer measures the time required to execute I/O operations on lower layers. It is ideal for performance and stress testing of <code>read</code>, <code>write</code>, <code>truncate</code> and other file operations within the modular I/O system. Note that <code>open</code> and <code>close</code> operations are excluded from benchmarking since they cannot be safely repeated multiple times without causing issues (e.g., too many open file descriptors or closing a file descriptor more than once).</p>"},{"location":"layers/benchmark/index.html#overview","title":"Overview","text":"<p>The benchmark layer provides:</p> <ul> <li>Accurate timing measurements for I/O operations</li> <li>Configurable operation repetition for more consistent results</li> <li>Transparent behavior to applications</li> <li>Performance evaluation of underlying layers</li> <li>Easy integration into layered I/O stacks</li> </ul>"},{"location":"layers/benchmark/index.html#key-features","title":"Key Features","text":"<ul> <li>Configurable operation repetitions (<code>reps</code>) to reduce measurement variability</li> <li>High-resolution timing using <code>clock_gettime(CLOCK_MONOTONIC)</code></li> <li>Direct output to <code>stdout</code> with the total elapsed time</li> <li>Independent measurement for reads and writes</li> <li>Transparent interface \u2014 applications remain unaware of the benchmarking layer</li> </ul>"},{"location":"layers/benchmark/index.html#usage-notes","title":"Usage Notes","text":"<p>The benchmark layer can be used to evaluate the overhead introduced by a specific layer by placing it:</p> <ul> <li>Above the target layer to measure the full stack including it</li> <li>Below the target layer to measure only what comes after</li> </ul> <p>You can then compare the results to estimate the cost of that specific layer.</p>"},{"location":"layers/benchmark/index.html#future-improvements","title":"Future Improvements","text":"<ul> <li>Support for measuring <code>open</code> and <code>close</code> operations</li> <li>Support for configurable runtime scripts to automate consistent tests</li> </ul>"},{"location":"layers/benchmark/index.html#configuration","title":"Configuration","text":"<p>To configure the benchmark layer in your <code>config.toml</code>:</p> <p>```toml [benchmark_layer] type = \"benchmark\" next = \"underlying_layer\"   # Name of the next layer in the chain reps = 100                  # Number of repetitions per operation (higher = more stable)</p>"},{"location":"layers/block_align/index.html","title":"Block Align Layer","text":"<p>The block align layer provides block-aligned I/O operations for the Modular IO Library. It ensures that all read and write operations are aligned to configurable block boundaries, optimizing performance for block-based storage systems.</p>"},{"location":"layers/block_align/index.html#overview","title":"Overview","text":"<p>The block align layer offers:</p> <ul> <li>Configurable block sizes for optimal alignment</li> <li>Automatic padding and alignment handling  </li> <li>Transparent operation for applications</li> <li>Performance optimization for block-based storage systems</li> <li>Hardware compatibility for systems requiring aligned I/O</li> </ul>"},{"location":"layers/block_align/index.html#block-align-layer_1","title":"Block Align Layer","text":"<p>The block align layer ensures data operations are aligned to specific block size boundaries, optimizing performance for storage systems that benefit from aligned I/O operations. This layer acts as an alignment adapter between layers with different block size requirements.</p>"},{"location":"layers/block_align/index.html#key-features","title":"Key Features","text":"<ul> <li>Configurable block alignment with customizable block sizes</li> <li>Automatic padding and alignment for optimal storage performance</li> <li>Transparent operation maintaining data integrity during alignment</li> <li>Performance optimization for block-oriented storage systems</li> </ul>"},{"location":"layers/block_align/index.html#configuration","title":"Configuration","text":"<p>To configure a block align layer in your <code>config.toml</code>, define it as follows:</p> <pre><code>[layer_name]\ntype = \"block_align\"\nnext = \"underlying_layer\"    # Name of the next layer in the chain\nblock_size = 4096           # Block size in bytes (optional, defaults to 4096)\n</code></pre> <p>Configuration Parameters:</p> <ul> <li><code>next</code> (required): Name of the underlying layer to forward aligned operations to</li> <li><code>block_size</code> (optional): Block size in bytes for alignment operations (defaults to 4096 if not specified)</li> </ul> <p>Usage Notes:</p> <ul> <li>Block sizes should typically be powers of 2 for optimal performance</li> <li>Common block sizes include 512, 1024, 4096, and 8192 bytes</li> <li>The <code>next</code> layer must be defined elsewhere in the configuration</li> <li>Alignment improves performance for certain storage backends and filesystems</li> </ul>"},{"location":"layers/block_align/index.html#features","title":"Features","text":"<ul> <li>Block Alignment: Ensures all I/O operations align to block boundaries</li> <li>Configurable Block Size: Supports various block sizes (512, 1024, 4096, etc.)</li> <li>Padding Handling: Automatically handles padding for non-aligned data</li> <li>Read Optimization: Reads full blocks and returns requested portions</li> <li>Write Optimization: Handles partial block writes efficiently</li> <li>Transparent Interface: Applications unaware of underlying alignment</li> </ul>"},{"location":"layers/block_align/index.html#architecture","title":"Architecture","text":""},{"location":"layers/block_align/index.html#block-alignment-concept","title":"Block Alignment Concept","text":"<pre><code>Application Request: Read 100 bytes at offset 50\nBlock Size: 512 bytes\n\nBlock-Aligned Operation:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Block 0 \u2502 Block 1 \u2502 Block 2 \u2502\n\u2502 512 B   \u2502 512 B   \u2502 512 B   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2191 offset 50\n     \u2514\u2500 Read full block, return bytes 50-149\n</code></pre>"},{"location":"layers/block_align/index.html#design-principles","title":"Design Principles","text":"<ul> <li>Alignment Strategy: All I/O operations aligned to block boundaries</li> <li>Buffer Management: Block-sized buffers for efficient operations</li> <li>Transparency: Applications see standard file operations</li> <li>Performance Focus: Optimizes for block-based storage characteristics</li> </ul>"},{"location":"layers/block_align/index.html#configuration_1","title":"Configuration","text":""},{"location":"layers/block_align/index.html#toml-configuration","title":"TOML Configuration","text":"<pre><code>[block_aligned_layer]\ntype = \"block_align\"\nblock_size = 4096    # Block size in bytes\n</code></pre>"},{"location":"layers/block_align/index.html#parameters","title":"Parameters","text":""},{"location":"layers/block_align/index.html#required-parameters","title":"Required Parameters","text":"<ul> <li><code>block_size</code> (integer): Size of blocks in bytes</li> <li>Common values: 512, 1024, 2048, 4096, 8192</li> <li>Requirement: Should be power of 2 for optimal performance</li> <li>Consideration: Should match underlying storage characteristics</li> </ul>"},{"location":"layers/block_align/index.html#block-size-selection-guidelines","title":"Block Size Selection Guidelines","text":"Block Size Use Case Performance Memory 512 Legacy systems, small files Good Low 1024 General purpose Good Low 4096 Modern SSDs, filesystems Optimal Moderate 8192 High-performance storage Best High"},{"location":"layers/block_align/index.html#operational-behavior","title":"Operational Behavior","text":""},{"location":"layers/block_align/index.html#read-operations","title":"Read Operations","text":"<ol> <li>Alignment Calculation: Determine which blocks contain requested data</li> <li>Block Boundary Adjustment: Expand read to include full blocks</li> <li>Underlying Read: Read aligned blocks from next layer</li> <li>Data Extraction: Extract requested portion from aligned data</li> <li>Result Return: Return only the requested data to application</li> </ol>"},{"location":"layers/block_align/index.html#write-operations","title":"Write Operations","text":"<ol> <li>Partial Block Handling: Handle writes not aligned to block boundaries</li> <li>Read-Modify-Write: Read existing blocks for partial modifications</li> <li>Data Merging: Merge new data with existing block content</li> <li>Block Write: Write complete modified blocks to next layer</li> <li>Optimization: Full block writes bypass read-modify-write cycle</li> </ol>"},{"location":"layers/block_align/index.html#file-size-management","title":"File Size Management","text":"<ul> <li>Size Tracking: Maintains actual file sizes separate from block-aligned storage</li> <li>Truncation Handling: Manages truncation to non-aligned sizes</li> <li>Size Queries: Returns actual file size (not block-aligned size)</li> </ul>"},{"location":"layers/block_align/index.html#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"layers/block_align/index.html#performance-benefits","title":"Performance Benefits","text":"<ul> <li>Storage Optimization: Aligns with underlying storage block sizes</li> <li>Hardware Efficiency: Reduces partial block operations</li> <li>Cache Efficiency: Better alignment with system page sizes</li> <li>I/O Reduction: Full block operations are more efficient</li> </ul>"},{"location":"layers/block_align/index.html#performance-costs","title":"Performance Costs","text":"<ul> <li>Read Amplification: May read more data than requested</li> <li>Write Amplification: Read-modify-write for partial blocks</li> <li>Memory Usage: Requires block-sized buffers</li> <li>CPU Overhead: Additional data copying and alignment calculations</li> </ul>"},{"location":"layers/block_align/index.html#optimization-strategies","title":"Optimization Strategies","text":"<p>Read-Heavy Workloads:</p> <ul> <li>Use larger block sizes (4096-8192 bytes)</li> <li>Match system page sizes for cache efficiency</li> <li>Consider access patterns when selecting block size</li> </ul> <p>Write-Heavy Workloads:  </p> <ul> <li>Use smaller block sizes to reduce read-modify-write overhead</li> <li>Align application writes to block boundaries when possible</li> <li>Monitor write amplification ratios</li> </ul> <p>Sequential Access:</p> <ul> <li>Use larger blocks for sequential throughput</li> <li>Consider underlying storage characteristics</li> <li>Balance memory usage with performance gains</li> </ul>"},{"location":"layers/block_align/index.html#thread-safety","title":"Thread Safety","text":"<p>The block align layer ensures thread safety through:</p> <ul> <li>Stateless Operations: Each operation is independent</li> <li>Read-Only Configuration: Block size is immutable after initialization</li> <li>Buffer Isolation: Each operation uses separate buffers</li> <li>Layer Delegation: Thread safety inherited from underlying layers</li> </ul>"},{"location":"layers/block_align/index.html#memory-management","title":"Memory Management","text":""},{"location":"layers/block_align/index.html#buffer-usage","title":"Buffer Usage","text":"<ul> <li>Temporary Buffers: Allocated per operation for alignment</li> <li>Block-Sized Allocations: Buffers sized to block boundaries</li> <li>Automatic Cleanup: Buffers freed after operations complete</li> <li>Memory Efficiency: Minimal persistent memory usage</li> </ul>"},{"location":"layers/block_align/index.html#memory-optimization","title":"Memory Optimization","text":"<ul> <li>Aligned Allocation: Uses aligned memory allocation for efficiency</li> <li>Buffer Reuse: Minimizes allocation overhead where possible</li> <li>Size Calculation: Optimizes buffer sizes for operations</li> </ul>"},{"location":"layers/block_align/index.html#error-handling","title":"Error Handling","text":""},{"location":"layers/block_align/index.html#alignment-errors","title":"Alignment Errors","text":"<ul> <li>Invalid Block Sizes: Validation during layer initialization</li> <li>Alignment Failures: Graceful fallback mechanisms</li> <li>Buffer Allocation Failures: Proper error handling and recovery</li> </ul>"},{"location":"layers/block_align/index.html#storage-errors","title":"Storage Errors","text":"<ul> <li>Layer Propagation: Underlying layer errors passed to application</li> <li>Partial Operations: Maintains consistency on operation failures</li> <li>State Management: Proper error state handling</li> </ul>"},{"location":"layers/block_align/index.html#hardware-considerations","title":"Hardware Considerations","text":""},{"location":"layers/block_align/index.html#ssd-optimization","title":"SSD Optimization","text":"<ul> <li>Page Size Alignment: 4KB blocks match SSD page sizes</li> <li>Write Amplification: Minimizes SSD write amplification</li> <li>Trim Support: Better interaction with SSD trim operations</li> </ul>"},{"location":"layers/block_align/index.html#hdd-optimization","title":"HDD Optimization","text":"<ul> <li>Sector Alignment: 512-byte alignment for traditional HDDs</li> <li>Track Alignment: Consider track sizes for sequential access</li> <li>Seek Reduction: Minimize head movement operations</li> </ul>"},{"location":"layers/block_align/index.html#network-storage","title":"Network Storage","text":"<ul> <li>Packet Alignment: Align with network packet sizes</li> <li>Protocol Efficiency: Reduce network protocol overhead</li> <li>Bandwidth Utilization: Optimize network resource usage</li> </ul>"},{"location":"layers/block_align/index.html#use-cases","title":"Use Cases","text":""},{"location":"layers/block_align/index.html#primary-applications","title":"Primary Applications","text":"<ul> <li>Database Storage: Align with database page sizes</li> <li>Virtual Machine Disks: Optimize VM disk I/O performance</li> <li>Media Streaming: Align with media block sizes</li> <li>High-Performance Computing: Optimize for parallel I/O operations</li> </ul>"},{"location":"layers/block_align/index.html#integration-scenarios","title":"Integration Scenarios","text":"<ul> <li>Storage Stack Optimization: As part of layered storage architectures</li> <li>Hardware Compatibility: Meeting hardware alignment requirements</li> <li>Performance Tuning: Optimizing for specific storage characteristics</li> <li>System Integration: Aligning with system memory and cache sizes</li> </ul>"},{"location":"layers/block_align/index.html#building-and-testing","title":"Building and Testing","text":""},{"location":"layers/block_align/index.html#build-commands","title":"Build Commands","text":"<pre><code># Build all components (includes block align layer)\nmake build\n\n# Or build just shared components (includes block align layer)\nmake shared/build\n\n# Run block align layer tests\nmake tests/run\n</code></pre>"},{"location":"layers/block_align/index.html#test-coverage","title":"Test Coverage","text":"<ul> <li>Various block sizes and alignment scenarios</li> <li>Partial block read/write operations</li> <li>File size and truncation handling</li> <li>Error condition testing and recovery</li> <li>Performance benchmarking and analysis</li> </ul>"},{"location":"layers/block_align/index.html#best-practices","title":"Best Practices","text":""},{"location":"layers/block_align/index.html#configuration-guidelines","title":"Configuration Guidelines","text":"<ul> <li>Block Size Selection: Match to underlying storage characteristics</li> <li>Access Pattern Analysis: Align configuration with usage patterns</li> <li>Memory Constraints: Balance performance vs memory usage</li> <li>Hardware Matching: Configure for target hardware platform</li> </ul>"},{"location":"layers/block_align/index.html#performance-tuning","title":"Performance Tuning","text":"<ul> <li>Monitoring: Track read/write amplification ratios</li> <li>Profiling: Monitor memory usage patterns</li> <li>Benchmarking: Test different block sizes for your workload</li> <li>Comparison: Benchmark against non-aligned operations</li> </ul>"},{"location":"layers/block_align/index.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"layers/block_align/index.html#common-issues","title":"Common Issues","text":"<ul> <li>Performance Degradation: Check block size vs access patterns alignment</li> <li>Memory Usage: Monitor buffer allocation and usage patterns</li> <li>Alignment Mismatches: Verify block size configuration appropriateness</li> <li>Compatibility Issues: Test with underlying storage systems</li> </ul>"},{"location":"layers/block_align/index.html#debugging-strategies","title":"Debugging Strategies","text":"<ol> <li>Enable debug logging: <code>log_mode = \"debug\"</code></li> <li>Monitor read/write amplification ratios</li> <li>Profile memory usage and allocation patterns</li> <li>Test different block sizes for your workload</li> <li>Benchmark performance against non-aligned operations</li> </ol>"},{"location":"layers/block_align/index.html#performance-analysis","title":"Performance Analysis","text":"<ul> <li>Access Pattern Monitoring: Analyze application I/O patterns</li> <li>Hardware Profiling: Understand underlying storage characteristics</li> <li>Memory Analysis: Monitor buffer usage and allocation efficiency</li> <li>Throughput Testing: Measure performance under various configurations</li> </ul>"},{"location":"layers/block_align/index.html#limitations","title":"Limitations","text":""},{"location":"layers/block_align/index.html#current-limitations","title":"Current Limitations","text":"<ul> <li>Fixed Block Size: Block size set at initialization time</li> <li>Memory Overhead: Requires additional memory for alignment buffers</li> <li>Read/Write Amplification: May increase I/O operations for small requests</li> <li>Configuration Complexity: Requires understanding of storage characteristics</li> <li>Append Atomicity: O_APPEND flag can't guarantee operation atomicity to ensure block aligment</li> </ul>"},{"location":"layers/block_align/index.html#design-trade-offs","title":"Design Trade-offs","text":"<ul> <li>Performance vs Memory: Larger blocks improve performance but use more memory</li> <li>Alignment vs Flexibility: Alignment improves performance but adds complexity</li> <li>Hardware Optimization vs Portability: Hardware-specific tuning reduces portability</li> </ul>"},{"location":"layers/block_align/index.html#future-enhancements","title":"Future Enhancements","text":""},{"location":"layers/block_align/index.html#planned-improvements","title":"Planned Improvements","text":"<ul> <li>Dynamic Block Sizing: Adjust block size based on access patterns</li> <li>Statistics Collection: Track alignment efficiency and performance metrics</li> <li>Auto-Configuration: Detect optimal block sizes automatically</li> <li>Advanced Optimization: NUMA-aware alignment and adaptive algorithms </li> </ul>"},{"location":"layers/cache/read_cache/index.html","title":"Read Cache Layer","text":"<p>A read cache layer introduces a caching layer for read operations in the modular I/O system. Its main goal is to reduce redundant accesses to lower layers (and consequently the disk or remote backends) by storing blocks of data that have already been read.  </p> <p>With this approach, subsequent reads to the same block are served directly from the cache, avoiding unnecessary I/O costs and improving overall performance.  </p>"},{"location":"layers/cache/read_cache/index.html#overview","title":"Overview","text":"<p>The read cache layer provides:</p> <ul> <li>In-memory caching for file blocks</li> <li>Automatic consistency management (invalidating or updating blocks when necessary, e.g., writes, truncates, unlinks, etc)</li> <li>Transparency for applications \u2014 no user code changes required</li> <li>Easy integration into any layer stack</li> </ul>"},{"location":"layers/cache/read_cache/index.html#key-features","title":"Key Features","text":"<ul> <li>Block-based caching defined by the <code>block_size</code> parameter</li> <li>Configurable number of blocks to cache </li> <li>Configurable block size, allowing to cache more or less data at once according to memory availability and performance needs</li> </ul>"},{"location":"layers/cache/read_cache/index.html#usage-notes","title":"Usage Notes","text":"<p>This layer currently works in synergy with block align to cache entire blocks, enhancing the performance of programs that exhibit spacial locality in their read requests.</p> <p>The layer can be used to:</p> <ul> <li>Improve performance of frequent reads in large files</li> <li>Avoid redundant reads in I/O-intensive workloads</li> </ul>"},{"location":"layers/cache/read_cache/index.html#future-improvements","title":"Future Improvements","text":"<ul> <li>Configurable block replacement policy (LRU, LFU, etc.)</li> <li>Thread-safe handling of cache pools</li> <li>Local disk caching for remote-heavy operations</li> </ul>"},{"location":"layers/cache/read_cache/index.html#configuration","title":"Configuration","text":"<p>Example configuration in <code>config.toml</code>:</p> <p>```toml [read_cache_layer] type = \"read_cache\" next = \"underlying_layer\"   # Name of the next layer in the stack block_size = 4096           # Size of each block in bytes. This value needs to be the same as the block_align block_size num_blocks = 1024           # Maximum number of blocks in cache</p>"},{"location":"layers/compression/index.html","title":"Compression Layer","text":"<p>The compression layer provides transparent data compression and decompression for the Modular IO Library. It supports multiple compression algorithms with configurable compression levels, offering a balance between compression ratio and performance.</p>"},{"location":"layers/compression/index.html#overview","title":"Overview","text":"<ul> <li>Transparent compression and decompression on read/write operations</li> <li>Multiple algorithms: Supports LZ4 and ZSTD</li> <li>Configurable compression levels</li> <li>Thread-safe: Path-based locking</li> <li>Original size tracking</li> <li>Layer-agnostic: Works with any underlying storage</li> <li>Currently only block-based mode is implemented</li> </ul>"},{"location":"layers/compression/index.html#supported-mode-sparse_block-block-alignment-important","title":"Supported Mode: sparse_block &amp; Block Alignment (IMPORTANT)","text":"<p>\u26a0\ufe0f Only the <code>sparse_block</code> mode is currently supported. This means data is compressed and decompressed per block of configurable size. It will only provide compression efficiencies with file systems that support sparse files.</p> <p>To work correctly, you MUST use the <code>block_align</code> layer directly above the compression layer, setting the same <code>block_size</code> in both. This ensures: - Data passed to compression is always in full-size blocks - Every block is compressed (and decompressed) independently</p> <p>Example TOML config: <pre><code>[block_align]\ntype = \"block_align\"\nblock_size = 262144\nnext = \"compression\"\n\n[compression]\ntype = \"compression\"\nalgorithm = \"lz4\"  # or \"zstd\"\nlevel = 1           # compression level (int)\nmode = \"sparse_block\"\nblock_size = 262144\nnext = \"underlying_layer\"\n\n[compression.options]\nfree_space = true\n</code></pre></p>"},{"location":"layers/compression/index.html#key-features","title":"Key Features","text":"<ul> <li>Algorithm support: LZ4 (fast) and ZSTD (high ratio), tunable compression levels</li> <li>Automatic operation: Transparently compresses/decompresses blocks on all I/O</li> <li>Size tracking: Maintains original file/block sizes for accurate decompression</li> <li>Thread safety: Per-path locking and reader-writer locks</li> <li>Memory efficiency: Dynamically manages buffers for optimal usage</li> </ul>"},{"location":"layers/compression/index.html#configuration","title":"Configuration","text":"<p>Define a compression layer in your <code>config.toml</code> as above. </p> <ul> <li><code>algorithm</code> (required): Compression algorithm, <code>lz4</code> or <code>zstd</code></li> <li><code>level</code> (integer): Compression level</li> <li>LZ4: Levels 0-12 (0=default, 12=best compression)(Negative values enable fast acceleration mode)</li> <li>ZSTD: Levels 0-22 (3=default, 22=best compression)(Negative values enable ultra-fast compression that prioritizes speed over compression ratio)</li> <li><code>mode</code> (required): Always <code>sparse_block</code> (required)</li> <li><code>block_size</code> (required): Must match above block_align</li> <li><code>next</code> (required): Next layer</li> <li><code>options</code>: <ul> <li><code>free_space</code>: Use <code>fallocate</code> (if available in the persistense layer) to punch holes in the file if the update to the block has a smaller size than before. This leads to space optimization, but may hurt the performance.</li> </ul> </li> </ul>"},{"location":"layers/compression/index.html#algorithm-characteristics","title":"Algorithm Characteristics","text":"<ul> <li><code>lz4</code>: Extremely fast, moderate ratio, low memory - ideal for real-time/data streaming</li> <li><code>zstd</code>: Fast (but slower than LZ4), better compression, moderate memory - best for storage/bandwidth savings</li> </ul>"},{"location":"layers/compression/index.html#mode-characteristics","title":"Mode Characteristics","text":""},{"location":"layers/compression/index.html#-sparse_block-each-blocks-starts-in-the-respective-offset-in-the-file-leaving-spaces-between-blocks-if-the-block-is-compressable-in-case-of-no-compression-gains-the-block-is-stored-uncompressed-most-file-systems-support-sparse-files-but-make-sure-that-your-fs-supports-it-if-not-no-gains-will-come-from-compression","title":"- <code>sparse_block</code>: Each blocks starts in the respective offset in the file, leaving spaces between blocks if the block is compressable. In case of no compression gains, the block is stored uncompressed. Most file systems support sparse files, but make sure that your fs supports it. If not, no gains will come from compression.","text":""},{"location":"layers/compression/index.html#architecture","title":"Architecture","text":""},{"location":"layers/compression/index.html#compression-flow","title":"Compression Flow","text":"<pre><code>Application Write \u2192 Compress Data (per block) \u2192 Store Compressed \u2192 Underlying Layer\nApplication Read  \u2190 Decompress Block-by-Block \u2190 Read Compressed \u2190 Underlying Layer\n</code></pre>"},{"location":"layers/compression/index.html#core-components","title":"Core Components","text":"<ul> <li>Size Mapping: Tracks original file sizes for decompression</li> <li>Compressor Interface: Pluggable algorithm support (easy future expansion)</li> <li>Locking System: Per-path &amp; per-block thread safety</li> <li>Buffer Management: Allocates buffers dynamically for compression/decompression</li> </ul>"},{"location":"layers/compression/index.html#operational-behavior","title":"Operational Behavior","text":""},{"location":"layers/compression/index.html#compression-write-operations","title":"Compression (Write Operations)","text":"<ol> <li>Acquire WRITE lock for file path</li> <li>Compress the write buffer (per block) using the selected algorithm</li> <li>Record the original size in the size hash table</li> <li>Write compressed block to next layer</li> <li>Release WRITE lock</li> </ol>"},{"location":"layers/compression/index.html#decompression-read-operations","title":"Decompression (Read Operations)","text":"<ol> <li>Acquire READ lock for file path</li> <li>Read compressed block data from the next layer</li> <li>Retrieve the original block size</li> <li>Decompress to original size</li> <li>Release READ lock</li> </ol>"},{"location":"layers/compression/index.html#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Compression adds some CPU overhead; using LZ4 gives maximum speed, ZSTD higher compression</li> <li>Matching <code>block_size</code> between <code>block_align</code> and compression is required for correctness and optimal performance</li> <li>Space savings vs. speed trade-off determined by level &amp; algorithm</li> </ul>"},{"location":"layers/compression/index.html#performance-guidelines","title":"Performance Guidelines","text":"<ul> <li>Maximum speed: LZ4 with level 1</li> <li>Maximum compression: ZSTD with high level</li> <li>Balanced: ZSTD with level 6</li> </ul>"},{"location":"layers/compression/index.html#storage-benefits","title":"Storage Benefits","text":"<ul> <li>Reduces on-disk and over-the-wire data size (if storage/fs supports sparse files)</li> <li>Decreases I/O and network usage</li> </ul>"},{"location":"layers/compression/index.html#pgbench-performance","title":"pgbench performance","text":"<p>We have done three steps to test the performance of sparse block compression: - run <code>initdb</code> script, and measure the disk space used - run data init <code>pgbench -i -s 50</code>, and measure the disk space used - run three times a workload of read/write queries for 5 minutes each run, collect the average transaction per second (TPS), and measure the disk space used in the end of the runs</p> <ul> <li>Platform: AWS EC2 m7i.xlarge (4 vCPUs, 16 GB RAM)</li> <li>OS: AlmaLinux 9.6 (Sage Margay)</li> <li>Database: PostgreSQL (v13.22) with pgbench benchmarking tool</li> </ul> <p>With this, we've gathered this data, which provides the following comparison:</p> Scenario Average TPS % Difference vs No Fuse (TPS) Size (before; after init; after runs) % Difference vs No Fuse (Space) No Fuse 3810.62 tps - 43M; 1.4G; 2.9G - Fuse with local 3379 tps -12% 43M; 1.4G; 2.9G - Fuse LZ4 256kb 2094.69 tps -45% 13M; 421M; 577M -70%; -70%; -81% Fuse LZ4 512kb 1531.36 tps -60% 11M; 272M; 436M -75%; -81%; -85% Fuse LZ4 256kb with fallocate 1276.46 tps -66% 13M; 421M; 541M -80%; -94%; -81.7% Fuse LZ4 512kb with fallocate 1037.29 tps -72% 11M; 272M; 393M -75%; -81%; -87%"},{"location":"layers/compression/index.html#algorithm-comparison","title":"Algorithm Comparison","text":"Algorithm Speed Compression Ratio CPU Usage Use Case LZ4 Very Fast Moderate Low Performance-critical applications ZSTD Fast High Moderate Storage-optimized applications"},{"location":"layers/compression/index.html#lz4","title":"LZ4","text":"<ul> <li>Speed: Extremely fast</li> <li>Ratio: 2-3x typical for text data</li> <li>Memory: Low requirements</li> <li>Best for: Real-time apps, networks, fast access</li> </ul>"},{"location":"layers/compression/index.html#zstd","title":"ZSTD","text":"<ul> <li>Speed: Fast (slower than LZ4)</li> <li>Ratio: 3-5x for text data</li> <li>Memory: Moderate requirements</li> <li>Best for: Backups, archives, bandwidth-constrained/cloud use</li> </ul>"},{"location":"layers/compression/index.html#thread-safety","title":"Thread Safety","text":"<ul> <li>Path-based and reader-writer locks prevent race conditions</li> <li>Size mapping and buffer management are thread-safe</li> </ul>"},{"location":"layers/compression/index.html#error-handling","title":"Error Handling","text":""},{"location":"layers/compression/index.html#compression-errors","title":"Compression Errors","text":"<ul> <li>Insufficient buffer? Automatic buffer resizing</li> <li>Algorithm init failure? Configuration validated at startup</li> <li>Compression failure? Falls back to storing uncompressed data</li> </ul>"},{"location":"layers/compression/index.html#decompression-errors","title":"Decompression Errors","text":"<ul> <li>Invalid compressed data? Detect and report</li> <li>Size mismatch? Validates against mapping</li> <li>Memory failures? Reports and recovers safely</li> <li>Decompression failure? Returns standard error</li> </ul>"},{"location":"layers/compression/index.html#recovery","title":"Recovery","text":"<ul> <li>Loss of size mapping attempts a best-effort size estimation</li> </ul>"},{"location":"layers/compression/index.html#building-testing","title":"Building &amp; Testing","text":"<pre><code>make build        # Build all, includes compression layer\nmake tests/run    # Run compression tests\n</code></pre>"},{"location":"layers/compression/index.html#test-coverage","title":"Test Coverage","text":"<ul> <li>Compression/decompression round-trips</li> <li>Each algorithm, compression level</li> <li>Error condition handling and reporting</li> <li>Thread safety validation under concurrency</li> <li>Performance and buffer efficiency</li> </ul>"},{"location":"layers/compression/index.html#memory-management","title":"Memory Management","text":"<ul> <li>Buffers sized dynamically to fit block data</li> <li>Reuse: Compression buffers reused where possible</li> <li>Cleanup: Automatic cleanup on layer destruction</li> <li>Size mapping: Efficient hash table for block/file mapping, auto cleanup</li> </ul>"},{"location":"layers/compression/index.html#troubleshooting","title":"Troubleshooting","text":"<ul> <li>High CPU usage? Lower level, use LZ4</li> <li>Memory? Monitor buffer/size-map use</li> <li>Size mismatches? Check mapping integrity</li> <li>Performance? Profile compression vs. I/O trade-off</li> <li>Debug logging: <code>log_mode = \"debug\"</code></li> </ul>"},{"location":"layers/compression/index.html#optimization-tips","title":"Optimization Tips","text":"<ul> <li>Match algorithm to use case</li> <li>Tune compression level for speed/space trade-off</li> <li>Monitor/tune buffer sizes for your workload</li> <li>Use block_align with matching size for reliability</li> </ul>"},{"location":"layers/compression/index.html#modular-compressor-interface","title":"Modular Compressor Interface","text":"<ul> <li>Uniform interface for algorithm selection at runtime</li> <li>Extensible by design: Add new compression algorithms easily</li> <li>Current implementations: LZ4 (via LZ4 library), ZSTD (Zstandard lib)</li> <li>Pluggable for new methods in future</li> </ul> <p>This extensible design enables future growth (modes and algorithms) while delivering efficient, safe, and configurable transparent compression for any storage backend. </p>"},{"location":"layers/demultiplexer/index.html","title":"Demultiplexer Layer","text":"<p>The demultiplexer layer routes operations across multiple underlying layers based on configurable policies. This layer enables parallel processing, load distribution, and redundancy by intelligently managing multiple storage backends.</p>"},{"location":"layers/demultiplexer/index.html#key-features","title":"Key Features","text":"<ul> <li>Multi-layer routing with configurable layer selection policies</li> <li>Passthrough operations for optimized read/write patterns</li> <li>Enforced layer support ensuring critical layers receive all operations  </li> <li>Dynamic load balancing across available storage backends</li> <li>Thread-safe coordination of concurrent operations</li> </ul>"},{"location":"layers/demultiplexer/index.html#configuration","title":"Configuration","text":"<pre><code>[layer_name]\ntype = \"demultiplexer\"\nlayers = [\"layer_1\", \"layer_2\", \"layer_3\"]    # Array of underlying layers\n\n[layer_name.options]\nenforced_layers = [\"layer_1\"]                 # Layers that must receive all operations (optional)\npassthrough_reads = [\"layer_2\"]               # Layers optimized for read operations (optional)  \npassthrough_writes = [\"layer_3\"]              # Layers optimized for write operations (optional)\n</code></pre> <p>Parameters: - <code>layers</code> (required): Array of layer names that this demultiplexer manages - <code>enforced_layers</code> (optional): Array of layer names that must receive all operations - <code>passthrough_reads</code> (optional): Array of layer names optimized for read operations - <code>passthrough_writes</code> (optional): Array of layer names optimized for write operations</p> <p>Usage Notes: - All layer names must correspond to other defined layers in the configuration - Layers can appear in multiple option arrays to combine behaviors - If not specified, the first layer becomes enforced and others are optional</p>"},{"location":"layers/demultiplexer/index.html#overview","title":"Overview","text":"<p>The demultiplexer creates a tree-like structure where a single operation is distributed across multiple underlying layers. It supports:</p> <ul> <li>Parallel Operations: All operations run concurrently across configured layers</li> <li>Enforced Layers: Critical layers that must succeed for the operation to succeed</li> <li>Passthrough Operations: Skip specific operations on certain layers for optimization</li> <li>Thread Safety: All operations are thread-safe with proper synchronization</li> </ul>"},{"location":"layers/demultiplexer/index.html#configuration-options","title":"Configuration Options","text":""},{"location":"layers/demultiplexer/index.html#required-parameters","title":"Required Parameters","text":"<ul> <li> <p><code>layers</code> (array of strings): List of layer names to multiplex operations across</p> </li> <li> <p>Must contain at least one layer</p> </li> <li>Layers are referenced by their configuration section names</li> </ul>"},{"location":"layers/demultiplexer/index.html#optional-parameters-in-options-table","title":"Optional Parameters (in <code>options</code> table)","text":""},{"location":"layers/demultiplexer/index.html#enforced_layers-array-of-strings","title":"<code>enforced_layers</code> (array of strings)","text":"<ul> <li>Purpose: Specify which layers must succeed for the operation to succeed</li> <li>Default: If not specified, the first layer becomes enforced and others are optional</li> <li>Behavior: Operation fails if any enforced layer fails</li> </ul>"},{"location":"layers/demultiplexer/index.html#passthrough_reads-array-of-strings","title":"<code>passthrough_reads</code> (array of strings)","text":"<ul> <li>Purpose: Skip read operations on specified layers</li> <li>Use Case: Write-only backup layers or layers that don't serve reads.</li> <li>Behavior: These layers return immediately without performing reads</li> </ul>"},{"location":"layers/demultiplexer/index.html#passthrough_writes-array-of-strings","title":"<code>passthrough_writes</code> (array of strings)","text":"<ul> <li>Purpose: Skip write operations on specified layers</li> <li>Use Case: Read-only cache layers or immutable storage</li> <li>Behavior: These layers return immediately without performing writes</li> </ul>"},{"location":"layers/demultiplexer/index.html#operational-behavior","title":"Operational Behavior","text":""},{"location":"layers/demultiplexer/index.html#parallel-execution","title":"Parallel Execution","text":"<p>All configured layers receive operations simultaneously:</p> <ul> <li>Concurrency: Operations execute in parallel threads</li> <li>Synchronization: Results are collected and aggregated</li> <li>Performance: Total operation time equals slowest layer time</li> </ul>"},{"location":"layers/demultiplexer/index.html#error-handling","title":"Error Handling","text":"<p>Error behavior depends on layer enforcement:</p> <ul> <li>Enforced layers: Any failure causes operation failure</li> <li>Optional layers: Failures are logged but don't fail the operation</li> <li>Result aggregation: Success determined by enforced layer results</li> </ul>"},{"location":"layers/demultiplexer/index.html#read-operations","title":"Read Operations","text":"<p>Read behavior with multiple layers:</p> <ul> <li>First success: Return data from first successful read</li> <li>Fallback: Try remaining layers if primary fails</li> <li>Consistency: No consistency guarantees between layers</li> </ul>"},{"location":"layers/demultiplexer/index.html#write-operations","title":"Write Operations","text":"<p>Write behavior with multiple layers:</p> <ul> <li>Parallel writes: All layers receive write operations</li> <li>Success criteria: Based on enforced layer configuration</li> <li>Partial failures: Optional layer failures don't prevent success</li> </ul>"},{"location":"layers/demultiplexer/index.html#validation-rules","title":"Validation Rules","text":"<p>The demultiplexer enforces validation rules at initialization:</p>"},{"location":"layers/demultiplexer/index.html#invalid-configurations","title":"Invalid Configurations","text":"<ul> <li>Both passthrough: Layer cannot skip both reads and writes</li> <li>All read passthrough: At least one layer must handle reads</li> <li>All write passthrough: At least one layer must handle writes</li> <li>Enforced with passthrough: If a layer is enforced, should not have passthroughs</li> </ul>"},{"location":"layers/demultiplexer/index.html#valid-configurations","title":"Valid Configurations","text":"<ul> <li>Mixed passthrough: Different layers can skip different operations</li> <li>Selective enforcement: Any subset of layers can be enforced</li> <li>Flexible combinations: Various layer arrangements are supported</li> </ul>"},{"location":"layers/demultiplexer/index.html#use-cases","title":"Use Cases","text":""},{"location":"layers/demultiplexer/index.html#data-redundancy","title":"Data Redundancy","text":"<p>Multiple storage backends for reliability:</p> <ul> <li>Local + Remote: Combine local and remote storage</li> <li>Multi-cloud: Distribute across different cloud providers</li> <li>Backup strategies: Primary storage with backup layers</li> </ul>"},{"location":"layers/demultiplexer/index.html#performance-optimization","title":"Performance Optimization","text":"<p>Layer-specific optimizations:</p> <ul> <li>Cache layers: Fast read-only caches</li> <li>Write-through: Immediate writes with background replication</li> <li>Passthrough optimization: Skip unnecessary operations</li> </ul>"},{"location":"layers/demultiplexer/index.html#hybrid-architectures","title":"Hybrid Architectures","text":"<p>Complex storage arrangements:</p> <ul> <li>Tiered storage: Different storage classes for different needs</li> <li>Specialized layers: Combine compression, encryption, and storage</li> <li>Development/Production: Different layer configs for different environments</li> </ul>"},{"location":"layers/demultiplexer/index.html#best-practices","title":"Best Practices","text":""},{"location":"layers/demultiplexer/index.html#configuration-design","title":"Configuration Design","text":"<ul> <li>Start simple: Begin with basic multi-layer setup</li> <li>Enforce critical layers: Mark essential storage as enforced</li> <li>Optimize with passthrough: Skip unnecessary operations</li> <li>Document layer purposes: Clear naming and documentation</li> </ul>"},{"location":"layers/demultiplexer/index.html#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Layer ordering: Place fastest layers first for reads</li> <li>Enforce judiciously: Only enforce truly critical layers</li> <li>Monitor performance: Track individual layer performance</li> <li>Consider passthrough: Skip operations that don't add value</li> </ul>"},{"location":"layers/demultiplexer/index.html#error-management","title":"Error Management","text":"<ul> <li>Plan for failures: Design for partial layer failures</li> <li>Monitor all layers: Track health of optional layers too</li> <li>Graceful degradation: Ensure system works with subset of layers</li> <li>Alert on enforcement failures: Monitor enforced layer health</li> </ul>"},{"location":"layers/encryption/index.html","title":"Encryption Layer","text":"<p>The encryption layer provides transparent data encryption and decryption. It ensures data confidentiality by encrypting data before passing it to subsequent layers.</p>"},{"location":"layers/encryption/index.html#overview","title":"Overview","text":"<p>The encryption layer features:</p> <ul> <li>Transparent encryption/decryption on read/write operations</li> <li>Block-based encryption with configurable block sizes</li> <li>Random access support for efficient I/O at any offset</li> <li>Extensible cipher support - currently implements AES-256-XTS only</li> <li>Layer-agnostic design working with any underlying storage</li> <li>Unique IVs per block for enhanced security, making it difficult to find inter-block patterns</li> </ul>"},{"location":"layers/encryption/index.html#configuration","title":"Configuration","text":"<p>The encryption layer supports two methods for providing the encryption key:</p>"},{"location":"layers/encryption/index.html#method-1-direct-key-configuration","title":"Method 1: Direct Key Configuration","text":"<p>Provide the encryption key directly in the configuration file:</p> <pre><code>[layer_name]\ntype = \"encryption\"\nnext = \"next_layer_name\"              # Name of the next layer in the chain\nblock_size = 4096                     # Block size in bytes for encryption operations (default: 4096, minimum: 16)\nencryption_key = \"your-64-char-hex-key-here\"  # 64-character hexadecimal key (256 bits)\n</code></pre>"},{"location":"layers/encryption/index.html#method-2-vaultopenbao-integration-recommended","title":"Method 2: Vault/OpenBao Integration (Recommended)","text":"<p>Fetch the encryption key from a HashiCorp Vault or OpenBao server at initialization:</p> <pre><code>[layer_name]\ntype = \"encryption\"\nnext = \"next_layer_name\"              # Name of the next layer in the chain\nblock_size = 4096                     # Block size in bytes\napi_key = \"your-vault-token\"          # Vault authentication token\nvault_addr = \"http://localhost:8200\"  # Vault server address\nsecret_path = \"v1/secret/data/myapp/encryption\"  # Path to the secret in Vault\n</code></pre> <p>Vault Configuration Details:</p> <ul> <li>api_key: The Vault token used for authentication (sent as <code>X-Vault-Token</code> header)</li> <li>vault_addr: The base URL of your Vault server</li> <li>secret_path: Path to the secret in Vault (e.g., <code>v1/secret/data/myapp/encryption</code>)</li> </ul> <p>OpenBao Integration: This feature has been tested and verified to work with OpenBao. See OPENBAO.md for a complete guide on deploying OpenBao and configuring it to provide encryption keys.</p> <p>The Vault server should return a JSON response with the key in the following format:</p> <pre><code>{\n  \"data\": {\n    \"data\": {\n      \"key\": \"7da46e98f9643f34e8a4c68079816ec1ca9bbf4c68a3e50f842808848df50119\"\n    }\n  }\n}\n</code></pre> <p>Example Vault/OpenBao Setup:</p> <pre><code># Store encryption key in Vault/OpenBao\nvault kv put secret/myapp/encryption key=\"7da46e98f9643f34e8a4c68079816ec1ca9bbf4c68a3e50f842808848df50119\"\n\n# Or using OpenBao (bao CLI)\nbin/bao kv put secret/myapp/encryption key=\"7da46e98f9643f34e8a4c68079816ec1ca9bbf4c68a3e50f842808848df50119\"\n\n# Test retrieval\ncurl -H \"X-Vault-Token: $VAULT_TOKEN\" \\\n     \"$VAULT_ADDR/v1/secret/data/myapp/encryption\"\n</code></pre> <p>Security Note: Using Vault/OpenBao integration is the recommended approach for production environments as it centralizes key management and avoids storing sensitive keys in configuration files.</p>"},{"location":"layers/encryption/index.html#block-encryption-example","title":"Block Encryption Example","text":"<pre><code>Data: 10KB write to file, Block Size: 4096 bytes\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Block 0  \u2502 Block 1  \u2502 Block 2  \u2502\n\u2502 4096 B   \u2502 4096 B   \u2502 1808 B   \u2502\n\u2502 IV=0     \u2502 IV=1     \u2502 IV=2     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2193          \u2193          \u2193\n  Encrypt    Encrypt    Encrypt\n     \u2193          \u2193          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Encrypted \u2502Encrypted \u2502Encrypted \u2502\n\u2502 4096 B   \u2502 4096 B   \u2502 1808 B   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"layers/encryption/index.html#supported-ciphers","title":"Supported Ciphers","text":""},{"location":"layers/encryption/index.html#aes-256-xts","title":"AES-256-XTS","text":"<ul> <li>Algorithm: AES-256 in XTS mode (XEX-based tweaked-codebook mode with ciphertext stealing)</li> <li>Key Size: 512 bits total (two 256-bit keys for XTS)</li> <li>Block Size: Minimum 16 bytes (AES block size)</li> <li>Characteristics:</li> <li>Designed specifically for disk/block encryption</li> <li>No ciphertext expansion (output size = input size)</li> <li>Supports independent block encryption/decryption (random access)</li> <li>Handles partial blocks \u2265 16 bytes</li> <li>NIST SP 800-38E compliant</li> </ul> <p>Why XTS Mode? \\ XTS is specifically designed for storage encryption, providing strong security without ciphertext expansion, which is ideal for block-based storage systems requiring random access patterns.</p> <p>XTS Mode Limitations    - No authentication: Does not provide integrity protection or tampering detection    - Minimum block size: Cannot encrypt data smaller than 16 bytes (AES block size)    - Pattern leakage: If not used properly, it is susceptible to traffic analysis and replay attacks    - Tweak dependency: Security relies on unique tweaks (IVs) per block</p>"},{"location":"layers/encryption/index.html#operational-behavior","title":"Operational Behavior","text":""},{"location":"layers/encryption/index.html#encryption-process-write-operations","title":"Encryption Process (Write Operations)","text":"<ol> <li>Divide data into block-sized chunks</li> <li>For each block, generate unique IV from block counter</li> <li>Encrypt block using configured cipher</li> <li>Write encrypted blocks to underlying layer</li> </ol>"},{"location":"layers/encryption/index.html#read-operations-decryption","title":"Read Operations (Decryption)","text":"<ol> <li>Read encrypted data from underlying layer</li> <li>Divide encrypted data into blocks based on the block size</li> <li>For each block, generate matching IV from block counter</li> <li>Decrypt block and return plaintext to application</li> </ol>"},{"location":"layers/encryption/index.html#iv-generation","title":"IV Generation","text":"<p>Each block uses a unique initialization vector derived from its position:</p> <pre><code>uint64_t block_counter = 0;\nunsigned char iv[16] = {0};\nmemcpy(iv, &amp;block_counter, sizeof(uint64_t));\nblock_counter++;\n</code></pre>"},{"location":"layers/encryption/index.html#security-limitations","title":"Security Limitations","text":"<p>NOT SUITABLE FOR PRODUCTION:</p> <ol> <li>No Integrity Protection:</li> <li>Provides confidentiality only (AES-XTS does not authenticate data)</li> <li> <p>Encrypted data can be modified or corrupted without detection (Anti-Tampering Layer can be used to add integrity protection)</p> </li> <li> <p>Hardcoded Key:</p> </li> <li>All files encrypted with the same key</li> <li> <p>Key is visible in source code</p> </li> <li> <p>Weak IV Generation:</p> </li> <li>IVs derived solely from block counters</li> <li>May not provide sufficient randomness for high-security</li> </ol>"},{"location":"layers/encryption/index.html#building-and-testing","title":"Building and Testing","text":""},{"location":"layers/encryption/index.html#build-commands","title":"Build Commands","text":"<pre><code># Build all components\nmake build\n\n# Build shared components only\nmake shared/build\n</code></pre>"},{"location":"layers/encryption/index.html#dependencies","title":"Dependencies","text":"<ul> <li>OpenSSL: Required for cryptographic operations</li> <li>libcurl: Required for Vault integration (fetching keys from remote server)</li> </ul> <pre><code># Debian/Ubuntu\nsudo apt install libssl-dev libcurl4-openssl-dev\n\n# Fedora/RHEL\nsudo dnf install openssl-devel libcurl-devel\n\n# macOS\nbrew install openssl curl\n</code></pre>"},{"location":"layers/encryption/index.html#future-work","title":"Future Work","text":"<ul> <li>Key management integration</li> <li>Better IV generation</li> <li>Support any size by adding padding</li> <li>Key rotation support</li> <li>Support for additional ciphers and modes</li> <li>Parallel block processing</li> </ul>"},{"location":"layers/encryption/OPENBAO.html","title":"OpenBao Setup: Store and Read an Encryption Key via API","text":"<p>This guide shows how to deploy OpenBao and configure it to provide encryption keys to the encryption layer.</p> <p>Note: The encryption layer's Vault integration has been tested and verified to work with OpenBao. OpenBao is a fork of HashiCorp Vault that maintains API compatibility.</p>"},{"location":"layers/encryption/OPENBAO.html#overview","title":"Overview","text":"<p>This guide covers:</p> <ul> <li>Running OpenBao locally (dev mode)</li> <li>Creating and storing an encryption key in KV v2</li> <li>Creating a read\u2011only policy for that key</li> <li>Creating a token that can read the key</li> </ul> <p>All commands assume you are in the OpenBao repository root.</p>"},{"location":"layers/encryption/OPENBAO.html#1-run-openbao","title":"1. Run OpenBao","text":""},{"location":"layers/encryption/OPENBAO.html#11-dev-mode-local-testing","title":"1.1 Dev mode (local testing)","text":"<p>Build and start the dev server (quick and insecure, for local use only):</p> <pre><code>make dev\nbin/bao server -dev\n</code></pre> <p>The server prints a Root Token, for example:</p> <pre><code>Root Token: s.sWvZjwpCL9ZevPW4un3eEjay\n</code></pre> <p>In a new terminal, set your environment:</p> <pre><code>export BAO_ADDR='http://127.0.0.1:8200'\nexport BAO_TOKEN='s.sWvZjwpCL9ZevPW4un3eEjay'  # paste your Root Token\n</code></pre> <p>Note: <code>server -dev</code> is for local development only (insecure for production).</p>"},{"location":"layers/encryption/OPENBAO.html#12-production-style-server-config-file","title":"1.2 Production-style server (config file)","text":"<p>For a more realistic deployment, run OpenBao with a configuration file instead of <code>-dev</code>.</p> <ol> <li>Create a config file, for example <code>config.hcl</code>:</li> </ol> <pre><code>storage \"file\" {\n  path = \"/opt/bao/data\"\n}\n\nlistener \"tcp\" {\n  address       = \"0.0.0.0:8200\"\n  tls_disable   = 0\n  tls_cert_file = \"/opt/bao/certs/server.crt\"\n  tls_key_file  = \"/opt/bao/certs/server.key\"\n}\n\ndisable_mlock = true\napi_addr      = \"https://your-hostname:8200\"\n</code></pre> <ul> <li>storage: points to a persistent directory on disk (create it and set permissions).</li> <li>listener: enables HTTPS on <code>0.0.0.0:8200</code> using your TLS cert and key.</li> <li> <p>Adjust paths and hostname for your environment.</p> </li> <li> <p>Start the server:</p> </li> </ul> <pre><code>bin/bao server -config=config.hcl\n</code></pre> <ol> <li>Initialize and unseal (first-time only):</li> </ol> <p>In another terminal:</p> <pre><code>export BAO_ADDR='https://your-hostname:8200'\n\n# Initialize\nbin/bao operator init -key-shares=1 -key-threshold=1\n</code></pre> <p>This prints:</p> <ul> <li>One unseal key</li> <li>One initial root token</li> </ul> <p>Unseal the server:</p> <pre><code>bin/bao operator unseal &lt;UNSEAL_KEY&gt;\n</code></pre> <p>Then set the root token in your shell (similar to dev mode):</p> <pre><code>export BAO_TOKEN='&lt;ROOT_TOKEN_FROM_INIT&gt;'\n</code></pre> <p>From this point on, the remaining steps in this guide (KV secret, policy, token, and API access) are the same whether you started OpenBao in dev mode or with a production config.</p>"},{"location":"layers/encryption/OPENBAO.html#2-create-and-store-an-encryption-key-in-kv-v2","title":"2. Create and store an encryption key in KV v2","text":""},{"location":"layers/encryption/OPENBAO.html#21-enable-kv-v2-if-not-already","title":"2.1 Enable KV v2 (if not already)","text":"<pre><code>bin/bao secrets enable -path=secret kv-v2\n</code></pre> <p>If it is already enabled, you can ignore the error about the mount existing.</p>"},{"location":"layers/encryption/OPENBAO.html#22-generate-and-store-a-256bit-key","title":"2.2 Generate and store a 256\u2011bit key","text":"<pre><code>ENC_KEY=\"$(openssl rand -hex 32)\"   # 32 bytes \u2192 64 hex chars\nbin/bao kv put secret/myapp/encryption key=\"$ENC_KEY\"\n</code></pre> <p>Verify that it was stored:</p> <pre><code>bin/bao kv get secret/myapp/encryption\n</code></pre> <p>You should see the secret value under <code>Data.key</code>.</p>"},{"location":"layers/encryption/OPENBAO.html#3-create-a-readonly-policy-for-that-key","title":"3. Create a read\u2011only policy for that key","text":"<p>Create a file named <code>encryptor.hcl</code> in the repo root with:</p> <pre><code>path \"secret/data/myapp/*\" {\n  capabilities = [\"read\"]\n}\n\npath \"secret/metadata/myapp/*\" {\n  capabilities = [\"read\"]\n}\n</code></pre> <p>Upload the policy (using the root token):</p> <pre><code>bin/bao policy write encryptor encryptor.hcl\nbin/bao policy read encryptor   # sanity check\n</code></pre> <p>This policy only allows <code>read</code> of that KV path (no write, delete, or list).</p>"},{"location":"layers/encryption/OPENBAO.html#4-create-a-token-that-can-read-the-key","title":"4. Create a token that can read the key","text":"<p>With <code>BAO_TOKEN</code> still set to the root token:</p> <pre><code>bin/bao token create -policy=encryptor -format=json\n</code></pre> <p>The output contains an <code>auth.client_token</code>. Example:</p> <pre><code>{\n  \"auth\": {\n    \"client_token\": \"s.QHdlEExO1IVdlNcy6ZXWeB5t\",\n    \"policies\": [\"default\", \"encryptor\"],\n    \"token_policies\": [\"default\", \"encryptor\"]\n  }\n}\n</code></pre> <p>Export this as your application token:</p> <pre><code>export APP_TOKEN='s.QHdlEExO1IVdlNcy6ZXWeB5t'\n</code></pre>"},{"location":"layers/encryption/OPENBAO.html#41-verify-capabilities-for-the-token","title":"4.1 Verify capabilities for the token","text":"<pre><code>bin/bao token capabilities \"$APP_TOKEN\" secret/data/myapp/encryption\n</code></pre> <p>Expected output:</p> <pre><code>read\n</code></pre>"},{"location":"layers/encryption/OPENBAO.html#42-read-the-key-via-cli-using-the-app-token","title":"4.2 Read the key via CLI using the app token","text":"<pre><code>BAO_TOKEN=\"$APP_TOKEN\" bin/bao kv get secret/myapp/encryption\n</code></pre> <p>You should see the secret value under <code>Data.key</code>.</p>"},{"location":"layers/encryption/OPENBAO.html#43-read-the-key-via-http-api","title":"4.3 Read the key via HTTP API","text":"<p>Use the application token as an HTTP header. OpenBao (like Vault) uses the <code>X-Vault-Token</code> header name:</p> <pre><code>curl \\\n  -H \"X-Vault-Token: $APP_TOKEN\" \\\n  \"$BAO_ADDR/v1/secret/data/myapp/encryption\"\n</code></pre> <p>You should get a JSON response similar to:</p> <pre><code>{\n  \"data\": {\n    \"data\": {\n      \"key\": \"7da46e98f9643f34e8a4c68079816ec1ca9bbf4c68a3e50f842808848df50119\"\n    },\n    \"metadata\": {\n      \"created_time\": \"2025-12-02T13:07:55.72449Z\",\n      \"deletion_time\": \"\",\n      \"destroyed\": false,\n      \"version\": 1\n    }\n  }\n}\n</code></pre> <p>The actual encryption key is at JSON path <code>data.data.key</code>.</p>"},{"location":"layers/encryption/OPENBAO.html#5-configure-the-encryption-layer","title":"5. Configure the Encryption Layer","text":"<p>Once your OpenBao server is running and you have created a token, configure the encryption layer in your <code>config.toml</code>:</p> <pre><code>[encryption_layer]\ntype = \"encryption\"\nnext = \"next_layer_name\"\nblock_size = 4096\napi_key = \"s.QHdlEExO1IVdlNcy6ZXWeB5t\"  # Your application token\nvault_addr = \"http://127.0.0.1:8200\"\nsecret_path = \"v1/secret/data/myapp/encryption\"\n</code></pre> <p>When the layer initializes, it will:</p> <ol> <li>Make an HTTP request to <code>http://127.0.0.1:8200/v1/secret/data/myapp/encryption</code></li> <li>Include the header <code>X-Vault-Token: s.QHdlEExO1IVdlNcy6ZXWeB5t</code></li> <li>Parse the JSON response and extract the key from <code>data.data.key</code></li> <li>Use that key for all encryption/decryption operations</li> </ol>"},{"location":"layers/encryption/OPENBAO.html#6-summary","title":"6. Summary","text":"<ul> <li>Dev server: <code>bin/bao server -dev</code> with <code>BAO_ADDR</code> and <code>BAO_TOKEN</code> set.</li> <li>Secret: stored in KV v2 at <code>secret/myapp/encryption</code>.</li> <li>Policy: <code>encryptor</code> policy grants read\u2011only access to <code>secret/data/myapp/*</code>.</li> <li>Token: created with <code>bin/bao token create -policy=encryptor</code>, used via:</li> <li>CLI: <code>BAO_TOKEN=\"$APP_TOKEN\" bin/bao kv get secret/myapp/encryption</code></li> <li>HTTP: <code>curl -H \"X-Vault-Token: $APP_TOKEN\" \"$BAO_ADDR/v1/secret/data/myapp/encryption\"</code></li> </ul>"},{"location":"layers/encryption/OPENBAO.html#additional-resources","title":"Additional Resources","text":"<ul> <li>OpenBao Documentation</li> <li>OpenBao GitHub Repository</li> </ul>"},{"location":"layers/invisible_storage/index.html","title":"Invisible Storage Layer","text":"<p>The invisible storage layer provides integration with invisible storage systems for the Modular IO Library. It enables applications to store and retrieve data using advanced invisibility techniques, leveraging external Rust-based invisible storage bindings.</p>"},{"location":"layers/invisible_storage/index.html#invisible-storage-layers","title":"Invisible Storage Layers","text":"<p>The invisible storage layers provide seamless integration with cloud storage services and blockchain networks, enabling data to be stored in distributed systems while maintaining the modular I/O interface. These layers abstract complex network protocols and authentication mechanisms.</p>"},{"location":"layers/invisible_storage/index.html#available-layer-types","title":"Available Layer Types","text":"<p>This directory contains implementations for:</p> <ul> <li>S3 OpenDAL Layer: Amazon S3-compatible storage services</li> <li>Solana Layer: Blockchain-based storage on the Solana network</li> <li>IPFS OpenDAL Layer: IPFS-compatible storage services</li> </ul>"},{"location":"layers/invisible_storage/index.html#configuration","title":"Configuration","text":""},{"location":"layers/invisible_storage/index.html#s3-opendal-layer","title":"S3 OpenDAL Layer","text":"<p>To configure an S3 OpenDAL layer in your <code>config.toml</code>, define it as follows:</p> <pre><code>[layer_name]\ntype = \"s3_opendal\"\nendpoint = \"https://s3.amazonaws.com\"          # S3 service endpoint\naccess_key_id = \"your_access_key\"              # AWS access key ID\nsecret_access_key = \"your_secret_key\"          # AWS secret access key\nbucket = \"your_bucket_name\"                    # S3 bucket name\nregion = \"us-east-1\"                           # AWS region\nroot = \"path/prefix\"                           # Root path prefix within bucket\n</code></pre> <p>S3 OpenDAL Configuration Parameters (all required):</p> <ul> <li><code>endpoint</code>: S3-compatible service endpoint URL</li> <li><code>access_key_id</code>: Authentication access key identifier</li> <li><code>secret_access_key</code>: Authentication secret key</li> <li><code>bucket</code>: Name of the S3 bucket for storage</li> <li><code>region</code>: AWS region or equivalent for the service</li> <li><code>root</code>: Path prefix for all files within the bucket</li> </ul>"},{"location":"layers/invisible_storage/index.html#solana-layer","title":"Solana Layer","text":"<p>To configure a Solana layer in your <code>config.toml</code>, define it as following this example:</p> <pre><code>[layer_name]\ntype = \"solana\"\nrpc_url = \"https://api.devnet.solana.com\"    # Solana RPC endpoint\nkeypair_path = \"/path/to/keypair.json\"             # Path to Solana keypair file\n</code></pre> <p>Solana Configuration Parameters (all required):</p> Parameter Description Example How to obtain Security notes rpc_url Solana RPC endpoint used for on-chain operations https://api.devnet.solana.com Public RPC (mainnet/devnet/testnet) or a private RPC Prefer trusted/private RPC if available keypair_path Absolute path to a Solana JSON keypair for authentication /home/user/.config/solana/id.json Create with solana-keygen or use existing keypair Protect file permissions (chmod 600)"},{"location":"layers/invisible_storage/index.html#ipfs-opendal-layer","title":"IPFS OpenDAL Layer","text":"<p>To configure an IPFS OpenDAL layer in your <code>config.toml</code>, define it as follows:</p> <pre><code>[layer_name]\ntype = \"ipfs_opendal\"\napi_endpoint = \"http://127.0.0.1:5001\"\nroot = \"/ipfs/\"\n</code></pre> <p>IPFS OpenDAL Configuration Parameters (all required):</p> <ul> <li><code>api_endpoint</code>: IPFS API endpoint URL</li> <li><code>root</code>: Path prefix for all files within the IPFS</li> </ul> <p>First time setup:</p> <p>If you don't have a keypair file, or want to create a new one, you can follow the following steps:</p> <p>I. Install Solana CLI:</p> <p>Follow the instructions here to install the Solana CLI. Tested with version v3.0.8.</p> <p>Note: The next steps are to configure for devnet, but you can use the same steps for mainnet or testnet.</p> <p>II. Configure your Solana CLI to use devnet:</p> <p>Run the following command in your terminal:</p> <pre><code>solana config set --url devnet\n</code></pre> <p>III. Get your wallet address:</p> <p>If you don't have a keypair, this command will generate one automatically:</p> <pre><code>solana address\n</code></pre> <p>IV. Get some SOL:</p> <p>The following command should airdrop 1 SOL to your wallet:</p> <pre><code>solana airdrop 1\n</code></pre> <p>V. Find Your Keypair File Path:</p> <p>To find the location of your keypair file, run:</p> <pre><code>solana config get\n</code></pre> <p>Look for the following line: <pre><code>Keypair Path: /Users/youruser/.config/solana/id.json\n</code></pre></p> <p>This is the path to your keypair file.</p> <p>VI. Add the Keypair Path to the Project Config:</p> <p>Paste the keypair path into your project\u2019s config file:</p> <pre><code>[solana_sdk]\ntype = \"solana\"\nrpc_url = \"https://api.devnet.solana.com\"\nkeypair_path = \"/Users/youruser/.config/solana/id.json\"\n</code></pre> <p>Usage Notes:</p> <ul> <li>All S3 OpenDAL parameters are required for proper authentication and operation</li> <li>Solana requires a valid keypair file with appropriate permissions</li> <li>Network connectivity and valid credentials are required for both layer types</li> <li>These layers handle complex networking and authentication internally</li> </ul>"},{"location":"layers/invisible_storage/index.html#overview","title":"Overview","text":"<p>The invisible storage layer offers:</p> <ul> <li>Invisible data storage using advanced steganographic techniques</li> <li>Integration with external Rust invisible storage library</li> <li>Covert operations that hide data existence from casual observation</li> <li>Security enhancement through data concealment</li> <li>Seamless interface matching standard storage operations</li> </ul>"},{"location":"layers/invisible_storage/index.html#features","title":"Features","text":"<ul> <li>Data Concealment: Stores data in ways that hide its existence</li> <li>Rust Integration: Uses high-performance Rust bindings for core operations  </li> <li>Steganographic Storage: Advanced techniques for data invisibility</li> <li>Security Layer: Adds security through obscurity</li> <li>Standard Interface: Compatible with existing layer architecture</li> <li>Performance: Optimized Rust implementation for efficiency</li> </ul>"},{"location":"layers/invisible_storage/index.html#architecture","title":"Architecture","text":""},{"location":"layers/invisible_storage/index.html#integration-model","title":"Integration Model","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Application   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Invisible Layer \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Rust Bindings  \u2502 \u2500\u2500\u2500\u2500 External invisible storage library\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Invisible Store \u2502 \u2500\u2500\u2500\u2500 Hidden/steganographic storage\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"layers/invisible_storage/index.html#external-dependencies","title":"External Dependencies","text":"<p>The invisible storage layer depends on:</p> <ul> <li>Rust invisible storage bindings: Located in <code>lib/invisible-storage-bindings/</code></li> <li>External Rust library: Provides core invisible storage functionality</li> <li>Native interface: C-compatible bindings for integration</li> </ul>"},{"location":"layers/invisible_storage/index.html#configuration_1","title":"Configuration","text":""},{"location":"layers/invisible_storage/index.html#toml-configuration","title":"TOML Configuration","text":"<pre><code>[invisible_layer]\ntype = \"invisible_storage\"\n# Configuration parameters depend on specific invisible storage implementation\n</code></pre>"},{"location":"layers/invisible_storage/index.html#building-dependencies","title":"Building Dependencies","text":""},{"location":"layers/invisible_storage/index.html#build-external-library","title":"Build External Library","text":"<pre><code># Build the Rust invisible storage library\nmake external/libinvisible/build\n\n# Or use the combined build command\nmake libinvisible/build\n</code></pre>"},{"location":"layers/invisible_storage/index.html#clean-external-library","title":"Clean External Library","text":"<pre><code># Clean the external library\nmake libinvisible/clean\n</code></pre>"},{"location":"layers/invisible_storage/index.html#layer-implementation","title":"Layer Implementation","text":""},{"location":"layers/invisible_storage/index.html#initialization","title":"Initialization","text":"<p>The invisible storage layer initializes by:</p> <ol> <li>Loading Rust bindings: Connects to external invisible storage library</li> <li>Configuration setup: Applies invisible storage configuration</li> <li>Interface creation: Creates standard layer interface</li> <li>Resource allocation: Allocates necessary resources</li> </ol>"},{"location":"layers/invisible_storage/index.html#operation-mapping","title":"Operation Mapping","text":"<p>Standard layer operations are mapped to invisible storage:</p> <ul> <li>Open: Initialize invisible file access</li> <li>Read: Read data from invisible storage</li> <li>Write: Write data to invisible storage  </li> <li>Close: Finalize invisible file operations</li> </ul>"},{"location":"layers/invisible_storage/index.html#example-application","title":"Example Application","text":""},{"location":"layers/invisible_storage/index.html#running-the-invisible-example","title":"Running the Invisible Example","text":"<pre><code># Build the invisible storage example\nmake examples/invisible/build\n\n# Run the example application\nmake examples/invisible/run\n</code></pre> <p>The invisible example demonstrates:</p> <ul> <li>Integration patterns: How to use invisible storage in applications</li> <li>Configuration: Proper setup for invisible storage operations</li> <li>Operations: Reading, writing, and managing invisible data</li> <li>Performance: Benchmarking invisible storage operations</li> </ul>"},{"location":"layers/invisible_storage/index.html#security-considerations","title":"Security Considerations","text":""},{"location":"layers/invisible_storage/index.html#security-benefits","title":"Security Benefits","text":"<ul> <li>Data concealment: Hides data existence from unauthorized observation</li> <li>Steganographic protection: Uses advanced hiding techniques</li> <li>Access control: Controls access to invisible data</li> <li>Covert channels: Enables covert communication channels</li> </ul>"},{"location":"layers/invisible_storage/index.html#security-limitations","title":"Security Limitations","text":"<ul> <li>Detection resistance: May not resist sophisticated detection methods  </li> <li>Performance overhead: Concealment techniques add processing overhead</li> <li>Dependency trust: Relies on security of external Rust library</li> <li>Key management: Requires secure key management for access</li> </ul>"},{"location":"layers/invisible_storage/index.html#best-practices","title":"Best Practices","text":"<ul> <li>Combine with encryption: Use alongside traditional encryption</li> <li>Key security: Securely manage access keys and credentials</li> <li>Detection testing: Test against detection tools</li> <li>Backup strategies: Maintain secure backup of invisible data access methods</li> </ul>"},{"location":"layers/invisible_storage/index.html#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"layers/invisible_storage/index.html#performance-factors","title":"Performance Factors","text":"<ul> <li>Rust implementation: High-performance core operations</li> <li>Concealment overhead: Additional processing for invisibility</li> <li>Storage medium: Performance depends on underlying storage</li> <li>Access patterns: Sequential vs random access performance</li> </ul>"},{"location":"layers/invisible_storage/index.html#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Batch operations: Group operations for efficiency</li> <li>Caching: Cache frequently accessed invisible data</li> <li>Async operations: Use asynchronous I/O where possible</li> <li>Memory management: Optimize buffer usage</li> </ul>"},{"location":"layers/invisible_storage/index.html#integration-testing","title":"Integration Testing","text":""},{"location":"layers/invisible_storage/index.html#development-testing","title":"Development Testing","text":"<pre><code># Run with invisible storage components  \nmake build                    # Build all components including invisible\nmake examples/invisible/run   # Test invisible storage integration\n</code></pre>"},{"location":"layers/invisible_storage/index.html#validation-steps","title":"Validation Steps","text":"<ol> <li>Library loading: Verify Rust bindings load correctly</li> <li>Operation testing: Test all layer operations</li> <li>Data integrity: Verify data consistency</li> <li>Performance testing: Benchmark operation performance</li> <li>Security testing: Validate concealment effectiveness</li> </ol>"},{"location":"layers/invisible_storage/index.html#external-library-management","title":"External Library Management","text":""},{"location":"layers/invisible_storage/index.html#submodule-management","title":"Submodule Management","text":"<pre><code># Initialize invisible storage submodule\ngit submodule update --init --recursive\n\n# Update to latest version\nmake submodules/fetch\n</code></pre>"},{"location":"layers/invisible_storage/index.html#build-system-integration","title":"Build System Integration","text":"<p>The invisible storage layer integrates with the build system:</p> <ul> <li>Automatic building: Built as part of main build process</li> <li>Dependency management: Handles Rust library dependencies</li> <li>Cross-platform: Supports multiple platforms</li> <li>Version tracking: Tracks external library versions</li> </ul>"},{"location":"layers/invisible_storage/index.html#error-handling","title":"Error Handling","text":""},{"location":"layers/invisible_storage/index.html#library-errors","title":"Library Errors","text":"<ul> <li>Load failures: External library loading issues</li> <li>Interface errors: Rust-C interface communication problems</li> <li>Configuration errors: Invalid invisible storage configuration</li> <li>Resource errors: Memory or resource allocation failures</li> </ul>"},{"location":"layers/invisible_storage/index.html#storage-errors","title":"Storage Errors","text":"<ul> <li>Invisibility failures: Data concealment operation failures</li> <li>Detection risks: Potential exposure of invisible data</li> <li>Corruption: Invisible data corruption or loss</li> <li>Access failures: Unable to access invisible storage</li> </ul>"},{"location":"layers/invisible_storage/index.html#recovery-mechanisms","title":"Recovery Mechanisms","text":"<ul> <li>Fallback storage: Fallback to visible storage on failures</li> <li>Error logging: Detailed error logging for debugging</li> <li>State recovery: Attempt recovery of invisible storage state</li> <li>Data rescue: Emergency data recovery procedures</li> </ul>"},{"location":"layers/invisible_storage/index.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"layers/invisible_storage/index.html#common-issues","title":"Common Issues","text":"<ul> <li>Library not found: External Rust library not built or installed</li> <li>Interface failures: Version mismatches between C and Rust code</li> <li>Performance issues: Excessive concealment overhead</li> <li>Detection warnings: Invisible data may be detectable</li> </ul>"},{"location":"layers/invisible_storage/index.html#debugging-steps","title":"Debugging Steps","text":"<ol> <li>Verify build: Ensure external library built successfully</li> <li>Check logs: Enable debug logging for detailed information</li> <li>Test isolation: Test invisible storage layer in isolation</li> <li>Validate config: Verify invisible storage configuration</li> <li>Performance profile: Profile operations for bottlenecks</li> </ol>"},{"location":"layers/invisible_storage/index.html#build-issues","title":"Build Issues","text":"<pre><code># Common build troubleshooting\nmake clean/all           # Clean all components including external\nmake libinvisible/build  # Rebuild external library\nmake build               # Rebuild entire project\n</code></pre>"},{"location":"layers/local/index.html","title":"Local Layer","text":"<p>The local layer provides direct access to the local filesystem, serving as a fundamental storage backend for the modular I/O system.</p>"},{"location":"layers/local/index.html#key-features","title":"Key Features","text":"<ul> <li>Direct filesystem access with native performance</li> <li>POSIX-compliant operations supporting standard file system semantics</li> <li>Terminal layer - does not delegate to other layers</li> <li>Thread-safe with OS-level guarantees</li> <li>Minimal overhead over direct system calls</li> </ul>"},{"location":"layers/local/index.html#configuration","title":"Configuration","text":"<pre><code>[local_layer]\ntype = \"local\"\n# No additional parameters required\n</code></pre> <p>The local layer has no configuration parameters - it uses the filesystem directly.</p>"},{"location":"layers/local/index.html#operations","title":"Operations","text":"<p>File Management: Open, close, size query, truncate I/O Operations: Positioned read/write at specific file offsets</p>"},{"location":"layers/local/index.html#performance-behavior","title":"Performance &amp; Behavior","text":"<p>Performance: Minimal overhead, relies on OS buffer cache Error Handling: Returns system call error codes directly Memory: Low memory usage, simple cleanup Thread Safety: Stateless design with OS-level guarantees</p>"},{"location":"layers/local/index.html#use-cases","title":"Use Cases","text":"<ul> <li>Simple Applications: Direct local file access without complexity</li> <li>Terminal Layer: End point for complex layer architectures</li> <li>Development/Testing: Simple backend for development and testing</li> <li>Backup Storage: Local backup destination in multi-backend setups</li> <li>Cache Implementation: Local caching for remote operations</li> </ul>"},{"location":"layers/local/index.html#building-and-testing","title":"Building and Testing","text":"<pre><code># Build all components\nmake build\n\n# Run tests\nmake tests/run\n</code></pre> <p>Test Coverage: File lifecycle operations, error handling, concurrent access, large file operations</p>"},{"location":"layers/local/index.html#best-practices","title":"Best Practices","text":"<ul> <li>File Permissions: Ensure proper filesystem permissions</li> <li>Path Validation: Validate file paths before operations</li> <li>Error Handling: Always check return codes from operations</li> <li>Resource Management: Properly manage file descriptors</li> <li>Buffer Sizing: Use appropriate buffer sizes for I/O operations</li> <li>System Limits: Be aware of OS file descriptor limits</li> </ul>"},{"location":"layers/local/index.html#limitations","title":"Limitations","text":"<ul> <li>Local Only: Cannot access remote filesystems</li> <li>No Advanced Features: No compression, encryption, or caching</li> <li>OS Dependent: Limited by operating system capabilities</li> <li>Basic Operations: Provides only fundamental file operations</li> </ul>"},{"location":"layers/local/index.html#troubleshooting","title":"Troubleshooting","text":"<p>Debugging: Enable debug logging, check error codes, verify paths/permissions, monitor system limits </p>"},{"location":"layers/remote/index.html","title":"Remote Layer","text":"<p>The remote layer provides access to distributed storage systems and remote backends, enabling the modular I/O system to work with networked storage infrastructures. This layer abstracts network communication protocols and manages remote connectivity.</p>"},{"location":"layers/remote/index.html#key-features","title":"Key Features","text":"<ul> <li>Network-aware operations with built-in connectivity management</li> <li>Protocol abstraction supporting various remote storage systems</li> <li>Connection pooling and retry mechanisms for robust network operations</li> <li>Thread-safe networking for concurrent remote access</li> </ul>"},{"location":"layers/remote/index.html#configuration","title":"Configuration","text":"<p>To configure a remote layer in your <code>config.toml</code>, define it as follows:</p> <pre><code>[layer_name]\ntype = \"remote\"\n</code></pre> <p>Configuration Parameters:</p> <p>The remote layer requires no additional configuration parameters in its current implementation. Remote connectivity details are managed internally.</p> <p>Usage Notes:</p> <ul> <li>Designed for integration with distributed storage systems</li> <li>Network latency and reliability considerations apply</li> <li>Suitable for cloud-based and distributed storage scenarios</li> </ul>"},{"location":"layers/remote/index.html#overview","title":"Overview","text":"<p>The remote layer implements:</p> <ul> <li>Network-based file operations over TCP sockets</li> <li>Client-server architecture for distributed storage</li> <li>Protocol abstraction for remote I/O operations</li> <li>Connection management and error handling</li> </ul>"},{"location":"layers/remote/index.html#features","title":"Features","text":"<ul> <li>Network Communication: TCP socket-based client-server protocol</li> <li>Remote I/O Operations: Full I/O operation support over network</li> <li>Connection Management: Handles connection establishment and cleanup</li> <li>Protocol Abstraction: Hides network complexity from applications</li> <li>Error Propagation: Maintains error semantics across network boundaries</li> </ul>"},{"location":"layers/remote/index.html#architecture","title":"Architecture","text":""},{"location":"layers/remote/index.html#client-server-model","title":"Client-Server Model","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    TCP/IP    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Client    \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502   Server    \u2502\n\u2502 (Layer)     \u2502   Protocol   \u2502 (Storage)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"layers/remote/index.html#communication-protocol","title":"Communication Protocol","text":"<p>The remote layer uses a custom message protocol that provides:</p> <ul> <li>Fixed-size messages for efficient parsing</li> <li>Binary protocol for optimal performance</li> <li>Synchronous operations with request-response pattern</li> <li>Error code propagation from server to client</li> </ul>"},{"location":"layers/remote/index.html#core-operations","title":"Core Operations","text":"<ul> <li>File Management: Open, close, and file metadata operations</li> <li>Data Transfer: Read and write operations with positioning support</li> <li>Error Handling: Network and filesystem error propagation</li> <li>Connection Control: Connection lifecycle management</li> </ul>"},{"location":"layers/remote/index.html#configuration_1","title":"Configuration","text":""},{"location":"layers/remote/index.html#toml-configuration","title":"TOML Configuration","text":"<pre><code>[remote_layer]\ntype = \"remote\"\n# Server connection details configured at compile time\n# Default: 127.0.0.1:5000\n</code></pre> <p>Note: Current implementation uses compile-time configuration for server endpoints.</p>"},{"location":"layers/remote/index.html#operational-behavior","title":"Operational Behavior","text":""},{"location":"layers/remote/index.html#connection-management","title":"Connection Management","text":"<ul> <li>Initialization: Automatic connection establishment on layer creation</li> <li>Persistence: Socket connection maintained in layer state</li> <li>Error Recovery: Network errors propagated to application</li> <li>Cleanup: Connection closed during layer destruction</li> </ul>"},{"location":"layers/remote/index.html#io-operation-flow","title":"I/O Operation Flow","text":""},{"location":"layers/remote/index.html#read-operations","title":"Read Operations","text":"<ol> <li>Request Construction: Client prepares read request message</li> <li>Network Transmission: Request sent to server via TCP</li> <li>Server Processing: Server performs local read operation</li> <li>Response Return: Server sends data and result back to client</li> <li>Result Delivery: Client returns data to application</li> </ol>"},{"location":"layers/remote/index.html#write-operations","title":"Write Operations","text":"<ol> <li>Data Packaging: Client packages write data in request message</li> <li>Network Transmission: Request with data sent to server</li> <li>Server Processing: Server performs local write operation</li> <li>Result Return: Server confirms operation success/failure</li> <li>Result Delivery: Client returns operation result to application</li> </ol>"},{"location":"layers/remote/index.html#server-integration","title":"Server Integration","text":""},{"location":"layers/remote/index.html#server-component","title":"Server Component","text":"<p>The remote layer works with the storage server component:</p> <ul> <li>Multi-client support: Handles multiple client connections</li> <li>Request processing: Processes remote I/O requests</li> <li>Local operations: Performs actual file operations server-side</li> <li>Result transmission: Returns operation results to clients</li> </ul>"},{"location":"layers/remote/index.html#server-management","title":"Server Management","text":"<pre><code># Server operations\nmake examples/storserver/build    # Build storage server\nmake examples/storserver/run      # Run storage server\n</code></pre>"},{"location":"layers/remote/index.html#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"layers/remote/index.html#network-considerations","title":"Network Considerations","text":"<ul> <li>Latency Impact: Network round-trip time affects all operations</li> <li>Bandwidth Utilization: Transfer efficiency depends on network capacity</li> <li>Protocol Overhead: Synchronous protocol introduces latency</li> <li>Buffer Management: Message buffer sizes affect transfer efficiency</li> </ul>"},{"location":"layers/remote/index.html#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Connection Reuse: Maintain persistent connections</li> <li>Batch Operations: Group multiple operations when possible</li> <li>Compression: Consider data compression for large transfers</li> <li>Async Support: Implement asynchronous operations for better throughput</li> </ul>"},{"location":"layers/remote/index.html#security-considerations","title":"Security Considerations","text":""},{"location":"layers/remote/index.html#current-security-model","title":"Current Security Model","text":"<ul> <li>Trust-based: Assumes trusted network environment</li> <li>No Authentication: No built-in client authentication</li> <li>Plaintext Communication: Data transmitted without encryption</li> <li>Basic Access Control: Limited server-side access controls</li> </ul>"},{"location":"layers/remote/index.html#security-recommendations","title":"Security Recommendations","text":"<ul> <li>Network Security: Use within secure/trusted networks</li> <li>Access Controls: Implement server-side access restrictions</li> <li>Encryption: Consider adding encryption for sensitive data</li> <li>Authentication: Implement client authentication mechanisms</li> </ul>"},{"location":"layers/remote/index.html#error-handling","title":"Error Handling","text":""},{"location":"layers/remote/index.html#network-level-errors","title":"Network-Level Errors","text":"<ul> <li>Connection failures: Server unavailability or network issues</li> <li>Communication errors: Socket errors and transmission failures</li> <li>Timeout conditions: Operations that exceed time limits</li> <li>Server crashes: Handling server-side failures</li> </ul>"},{"location":"layers/remote/index.html#file-system-errors","title":"File System Errors","text":"<ul> <li>Remote filesystem errors: Server-side file operation failures</li> <li>Permission issues: Access denied on remote system</li> <li>Resource constraints: Server-side disk space or file limits</li> <li>Path resolution: Remote path validation and resolution errors</li> </ul>"},{"location":"layers/remote/index.html#building-and-testing","title":"Building and Testing","text":""},{"location":"layers/remote/index.html#build-commands","title":"Build Commands","text":"<pre><code># Build all components (includes remote layer)\nmake build\n\n# Or build just shared components (includes remote layer)\nmake shared/build\n\n# Build and run server component\nmake examples/storserver/build\nmake examples/storserver/run\n\n# Run remote layer tests (requires server)\nmake tests/run\n</code></pre>"},{"location":"layers/remote/index.html#test-requirements","title":"Test Requirements","text":"<ul> <li>Server dependency: Tests require running storage server</li> <li>Network connectivity: Local network access for testing</li> <li>Integration testing: Multi-component testing scenarios</li> </ul>"},{"location":"layers/remote/index.html#use-cases","title":"Use Cases","text":""},{"location":"layers/remote/index.html#distributed-storage-scenarios","title":"Distributed Storage Scenarios","text":"<ul> <li>Remote backup: Off-site data backup and replication</li> <li>Centralized storage: Shared storage across multiple clients</li> <li>Load distribution: Distribute storage across multiple servers</li> <li>Disaster recovery: Remote site redundancy</li> </ul>"},{"location":"layers/remote/index.html#integration-patterns","title":"Integration Patterns","text":"<ul> <li>Multi-backend systems: Combine with local storage for redundancy</li> <li>Cache hierarchies: Remote storage as backing store for local cache</li> <li>Distributed applications: Storage layer for distributed systems</li> <li>Development environments: Remote storage for development/testing</li> </ul>"},{"location":"scripts/postgresql/index.html","title":"PostgreSQL pgbench Workload Script","text":"<p>A comprehensive bash script for running PostgreSQL pgbench performance tests with automatic database setup, disk usage monitoring, and detailed metrics reporting.</p>"},{"location":"scripts/postgresql/index.html#overview","title":"Overview","text":"<p>This script automates the process of: - Creating a PostgreSQL database - Initializing pgbench with a scale factor of 50 - Running multiple pgbench test iterations - Monitoring disk usage at different stages - Calculating and reporting average latency and TPS metrics</p>"},{"location":"scripts/postgresql/index.html#prerequisites","title":"Prerequisites","text":"<ul> <li>PostgreSQL server running and accessible</li> <li><code>pgbench</code> utility installed</li> <li><code>psql</code> and <code>createdb</code> utilities available</li> <li><code>bc</code> calculator for metric calculations</li> <li>Appropriate database user permissions</li> </ul>"},{"location":"scripts/postgresql/index.html#setup","title":"Setup","text":"<p>Before running the pgbench workload script, you must initialize the PostgreSQL data directory and start the server.</p> <p>Note: PostgreSQL binaries are typically located in: - <code>/usr/bin/</code> (default on most Linux distributions) - <code>/usr/lib/postgresql/16/bin/</code> (Ubuntu/Debian specific version) - <code>/lib/postgresql/16/bin/</code> (alternative location)</p> <p>Adjust the paths below according to your PostgreSQL installation.</p>"},{"location":"scripts/postgresql/index.html#1-initialize-the-database","title":"1. Initialize the Database","text":"<p>Initialize a new PostgreSQL database cluster:</p> <pre><code>initdb -D examples/fuse/mount_point/\n\n# Example with full path:\n# /usr/lib/postgresql/16/bin/initdb -D examples/fuse/mount_point/\n</code></pre> <p>This creates a new PostgreSQL data directory at <code>examples/fuse/mount_point/</code>.</p>"},{"location":"scripts/postgresql/index.html#2-start-the-postgresql-server","title":"2. Start the PostgreSQL Server","text":"<p>If this step isn't working, remember to change the <code>unix_socket_directories</code> path to use <code>/tmp</code>, and create the folder with: <pre><code>mkdir -p /tmp/postgresql &amp;&amp; chmod 1777 /tmp/postgresql\n</code></pre></p> <p>Start the PostgreSQL server using the initialized data directory:</p> <pre><code># Example: Start server in the background\npostgres -D examples/fuse/mount_point/ &amp;\n\n# Or use pg_ctl for better control\npg_ctl -D examples/fuse/mount_point/ start\n\n# Example with full path:\n# /usr/lib/postgresql/16/bin/pg_ctl -D examples/fuse/mount_point/ start\n</code></pre> <p>Note: Adjust the data directory location according to your desired configuration.</p>"},{"location":"scripts/postgresql/index.html#3-verify-server-is-running","title":"3. Verify Server is Running","text":"<p>Check that the server is accepting connections:</p> <pre><code>pg_isready -h 127.0.0.1\n</code></pre> <p>Once the server is running and accessible, you can proceed to run the pgbench workload script.</p>"},{"location":"scripts/postgresql/index.html#usage","title":"Usage","text":"<pre><code>./pgbench_workload.sh --data-dir DIR --postgres-bin DIR [OPTIONS]\n</code></pre>"},{"location":"scripts/postgresql/index.html#stop-server","title":"Stop server","text":"<pre><code>pg_ctl -D examples/fuse/mount_point/ -l logfile stop\n\n# Example with full path:\n# /usr/lib/postgresql/16/bin/pg_ctl -D examples/fuse/mount_point/ -l logfile stop\n</code></pre>"},{"location":"scripts/postgresql/index.html#required-parameters","title":"Required Parameters","text":"Option Description <code>--data-dir DIR</code> REQUIRED PostgreSQL data directory to monitor <code>--postgres-bin DIR</code> REQUIRED Directory containing PostgreSQL binaries"},{"location":"scripts/postgresql/index.html#optional-parameters","title":"Optional Parameters","text":"Option Description Default <code>--db-name NAME</code> Database name to create/use <code>mydb</code> <code>--db-user USER</code> PostgreSQL user for connections <code>postgres</code> <code>--host HOST</code> Database host address <code>127.0.0.1</code> <code>--pgbench-bin PATH</code> Full path to pgbench binary <code>/usr/bin/pgbench</code> <code>--repeats N</code> Number of test runs to execute <code>3</code> <code>--duration SECONDS</code> Duration of each test run in seconds <code>300</code> <code>--read-only [0\\|1\\|true\\|false]</code> Enable read-only mode (adds <code>-S</code> flag) <code>1</code> (enabled) <code>-h, --help</code> Display help message -"},{"location":"scripts/postgresql/index.html#examples","title":"Examples","text":"<p>Note: All examples require <code>--data-dir</code> and <code>--postgres-bin</code> parameters. These are mandatory and have no default values.</p>"},{"location":"scripts/postgresql/index.html#basic-usage","title":"Basic Usage","text":"<p>Run with all default settings (required parameters must be provided): <pre><code>./pgbench_workload.sh \\\n    --data-dir /home/admin/Modular-IO-Lib/examples/fuse/mount_point \\\n    --postgres-bin /usr/bin\n</code></pre></p> <p>This will: - Create database <code>mydb</code> (or use existing) - Run 3 test iterations - Each test runs for 300 seconds (5 minutes) - Use read-only mode (<code>-S</code> flag)</p>"},{"location":"scripts/postgresql/index.html#custom-database-and-duration","title":"Custom Database and Duration","text":"<p>Run with a custom database name and longer test duration: <pre><code>./pgbench_workload.sh \\\n    --data-dir /home/admin/Modular-IO-Lib/examples/fuse/mount_point \\\n    --postgres-bin /usr/bin \\\n    --db-name testdb \\\n    --duration 600\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#read-write-mode","title":"Read-Write Mode","text":"<p>Run in read-write mode (disables <code>-S</code> flag) with shorter duration: <pre><code>./pgbench_workload.sh \\\n    --data-dir /home/admin/Modular-IO-Lib/examples/fuse/mount_point \\\n    --postgres-bin /usr/bin \\\n    --read-only 0 \\\n    --duration 120\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#multiple-test-runs","title":"Multiple Test Runs","text":"<p>Run 10 test iterations to get better statistical averages: <pre><code>./pgbench_workload.sh \\\n    --data-dir /home/admin/Modular-IO-Lib/examples/fuse/mount_point \\\n    --postgres-bin /usr/bin \\\n    --repeats 10 \\\n    --duration 300\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#remote-database","title":"Remote Database","text":"<p>Connect to a remote PostgreSQL server: <pre><code>./pgbench_workload.sh \\\n    --data-dir /var/lib/postgresql/data \\\n    --postgres-bin /usr/bin \\\n    --host 192.168.1.100 \\\n    --db-user myuser \\\n    --db-name production_test\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#custom-postgresql-installation","title":"Custom PostgreSQL Installation","text":"<p>Use a custom PostgreSQL installation path: <pre><code>./pgbench_workload.sh \\\n    --data-dir /var/lib/postgresql/16/data \\\n    --postgres-bin /usr/lib/postgresql/16/bin \\\n    --pgbench-bin /usr/lib/postgresql/16/bin/pgbench\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#full-custom-configuration","title":"Full Custom Configuration","text":"<p>Complete example with all options customized: <pre><code>./pgbench_workload.sh \\\n    --data-dir /var/lib/postgresql/data \\\n    --postgres-bin /usr/bin \\\n    --db-name benchmark_db \\\n    --db-user jnuno \\\n    --host localhost \\\n    --pgbench-bin /usr/bin/pgbench \\\n    --repeats 5 \\\n    --duration 600 \\\n    --read-only 1\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#quick-performance-test","title":"Quick Performance Test","text":"<p>Run a quick 1-minute test in read-write mode: <pre><code>./pgbench_workload.sh \\\n    --data-dir /home/admin/Modular-IO-Lib/examples/fuse/mount_point \\\n    --postgres-bin /usr/bin \\\n    --duration 60 \\\n    --read-only 0 \\\n    --repeats 1\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#script-workflow","title":"Script Workflow","text":"<ol> <li>Disk Usage Check (Before): Records disk usage of the data directory before database creation</li> <li>Database Creation: Creates the specified database (or uses existing)</li> <li>pgbench Initialization: Initializes pgbench with scale factor 50 (<code>-i -s 50</code>)</li> <li>Disk Usage Check (After Init): Records disk usage after initialization</li> <li>Test Execution: Runs pgbench tests the specified number of times</li> <li>Each test runs for the specified duration</li> <li>10 clients (<code>-c 10</code>) and 2 threads (<code>-j 2</code>) are used</li> <li>Read-only mode (<code>-S</code>) is enabled by default</li> <li>Disk Usage Check (After Tests): Records final disk usage</li> <li>Results Summary: Displays average latency and TPS across all runs, along with standard deviations to measure consistency</li> </ol>"},{"location":"scripts/postgresql/index.html#output-files","title":"Output Files","text":"<p>The script generates temporary result files:</p> <ul> <li><code>/tmp/tps_results.txt</code>: Detailed pgbench output for each test run</li> <li><code>/tmp/disk_usage_results.txt</code>: Disk usage measurements at different stages</li> </ul>"},{"location":"scripts/postgresql/index.html#metrics-reported","title":"Metrics Reported","text":"<ul> <li>Latency Average: Average transaction latency in milliseconds (across all runs)</li> <li>Latency Standard Deviation: Variability of transaction latency across runs</li> <li>TPS Average: Average transactions per second (across all runs)</li> <li>TPS Standard Deviation: Variability of TPS across runs</li> <li>Disk Usage: Before database creation, after initialization, and after all tests</li> </ul>"},{"location":"scripts/postgresql/index.html#pgbench-parameters","title":"pgbench Parameters","text":"<p>The script uses the following pgbench parameters: - <code>-c 10</code>: 10 concurrent clients - <code>-j 2</code>: 2 worker threads - <code>-S</code>: Read-only mode (when <code>--read-only</code> is enabled) - <code>-T DURATION</code>: Test duration in seconds - <code>-i -s 50</code>: Initialization with scale factor 50</p>"},{"location":"scripts/postgresql/index.html#read-only-mode","title":"Read-Only Mode","text":"<p>The <code>--read-only</code> flag controls whether pgbench runs in read-only mode: - <code>1</code>, <code>true</code>, <code>yes</code>, or any non-zero value: Enables read-only mode (adds <code>-S</code> flag) - <code>0</code>, <code>false</code>, or <code>no</code>: Disables read-only mode (read-write workload)</p>"},{"location":"scripts/postgresql/index.html#error-handling","title":"Error Handling","text":"<ul> <li>The script uses <code>set -e</code> to exit on any error</li> <li>Required parameters validation: Script exits with an error if <code>--data-dir</code> or <code>--postgres-bin</code> are not provided</li> <li>Database creation failures are handled gracefully (assumes database already exists)</li> <li>Missing directories are reported but don't stop execution</li> <li>Invalid command-line options display an error and show usage</li> </ul>"},{"location":"scripts/postgresql/index.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"scripts/postgresql/index.html#connection-issues","title":"Connection Issues","text":"<p>If you encounter connection errors: <pre><code># Check if PostgreSQL is running\npg_isready -h 127.0.0.1\n\n# Verify user permissions\npsql -h 127.0.0.1 -U your_user -d postgres -c \"\\du\"\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#permission-errors","title":"Permission Errors","text":"<p>Ensure your database user has: - <code>CREATE DATABASE</code> privilege - Access to the target database - Appropriate permissions for pgbench operations</p>"},{"location":"scripts/postgresql/index.html#missing-dependencies","title":"Missing Dependencies","text":"<p>Install required tools: <pre><code># Ubuntu/Debian\nsudo apt-get install postgresql-client postgresql-contrib bc\n\n# CentOS/RHEL\nsudo yum install postgresql postgresql-contrib bc\n</code></pre></p>"},{"location":"scripts/postgresql/index.html#notes","title":"Notes","text":"<ul> <li>The script waits 10 seconds between test runs</li> <li>Scale factor 50 creates a moderately sized test database</li> <li>Results are written to <code>/tmp/</code> and may be overwritten by subsequent runs</li> <li>The script will attempt to create the database; if it already exists, it will continue</li> </ul>"},{"location":"scripts/postgresql/index.html#see-also","title":"See Also","text":"<ul> <li>PostgreSQL pgbench Documentation</li> <li>PostgreSQL performance tuning guides</li> </ul>"},{"location":"scripts/read_cache/index.html","title":"Read_cache Layer Benchmark","text":"<p>\u26a0\ufe0f Warning: This script overwrites the <code>config.toml</code> file located at the root of the project. Make sure to back up your configuration before running it.</p>"},{"location":"scripts/read_cache/index.html#overview","title":"Overview","text":"<p>This benchmark script automates the evaluation of the read_cache layer in a storage stack configuration. It compares I/O performance between setups with and without the read_cache layer, under a compression-enabled environment.  </p> <p>It uses the <code>fio</code> tool to perform I/O operations such as sequential/random reads, measuring the impact of caching on performance.</p>"},{"location":"scripts/read_cache/index.html#operation","title":"Operation","text":"<p>The script dynamically: 1. Generates a <code>config.toml</code> with and without the read_cache layer. 2. Builds and runs the FUSE filesystem. 3. Executes benchmarks using <code>fio</code> with the user-specified parameters. 4. Stops and cleans up the running FUSE instance after tests.</p> <p>The two benchmark phases are: - Phase 1: compression and read_cache - Phase 2: only compression</p> <p>The workload generated by this benchmark is skewed in order to simulate an appropriate testing environment for the cache. This means some parts of the file (hot zone) are accessed more frequently than others. The hot zone generated is 5% of the total file, so for example, if using a 1GB file the hot zone will be around 50MB.</p>"},{"location":"scripts/read_cache/index.html#parameters","title":"Parameters","text":"<p>The script accepts multiple options that influence the compression and caching configuration:</p> Option Description Default <code>--compress_alg ALG</code> Compression algorithm (<code>zstd</code> and <code>lz4</code>) <code>lz4</code> <code>--compress_level N</code> Compression level (<code>lz4</code>: <code>-3</code> to <code>12</code>; <code>zstd</code>: <code>-5</code> to <code>22</code>) <code>0</code> <code>--size SIZE</code> File size for I/O test (<code>1G</code>, <code>500M</code>, <code>100K</code>, etc.) <code>500M</code> <code>--duration SEC</code> Duration of the benchmark in seconds <code>300</code> <code>--bs SIZE</code> Block size in bytes for the layer configuration (<code>4096</code> (4K), <code>262144</code> (256K), <code>1048576</code> (1M), etc.) <code>262144</code> <code>--num_blocks</code> Aproximated maximum number of blocks in the cache 400 <code>-h</code>, <code>--help</code> Display help information \u2014"},{"location":"scripts/read_cache/index.html#example-usage","title":"Example Usage","text":"<p>```bash ./read_cache_benchmark.sh --compress_alg=zstd --compress_level=9 --size=1G --duration=60 --bs=4k --num_blocks=100</p>"},{"location":"services/index.html","title":"Metadata Service","text":"<p>This README describes how the persistent metadata service works and its public API.</p>"},{"location":"services/index.html#overview","title":"Overview","text":"<p>The persistent metadata service provides:</p> <ul> <li>Generic way to store metadata across the whole project.</li> <li>Persistent metadata storage, allowing metadata to be reloaded when the program using the library restarts.</li> </ul>"},{"location":"services/index.html#key-features","title":"Key Features","text":"<ul> <li>Use of RocksDB to ensure thread safety and high performance.</li> <li>Simple API for simple and homogeneous usage across the codebase.</li> </ul>"},{"location":"services/index.html#api","title":"API","text":"<ul> <li> <p>metadata_init   Initializes the metadata service and allocates all required internal structures.   It receives a <code>ServiceConfig</code> structure that configures a variety of RocksDB's   parameters (currently, only the number of background threads and the cache size   are supported).</p> </li> <li> <p>metadata_put   Stores or updates metadata associated with a given key.</p> </li> <li> <p>metadata_get   Retrieves metadata associated with a given key.   Returns a pointer to memory allocated internally by the service, which must   be freed using <code>metadata_free(...)</code>.</p> </li> <li> <p>metadata_delete   Removes metadata associated with a given key.</p> </li> <li> <p>metadata_free   Frees any memory returned by the metadata service that was allocated internally   (for example, by <code>metadata_get</code>).</p> </li> <li> <p>metadata_close   Shuts down the metadata service and releases all internal resources.</p> </li> </ul>"},{"location":"services/index.html#how-to-use","title":"How to use","text":"<pre><code>  // called when initializing the library, so no need to call this in a layer\n  metadata_init(NULL);\n\n  char *key = \"key_test\";\n  char *value = \"test\";\n  size_t value_size;\n\n  int ret = metadata_put(key, strlen(key), value, strlen(value) + 1);\n\n  void* ret_value = metadata_get(key, strlen(key), &amp;value_size);\n  metadata_free(ret_value);\n\n  // like init, this shouldn't be called in a layer\n  metadata_close();\n</code></pre>"},{"location":"services/index.html#example-toml-config","title":"Example TOML config:","text":"<pre><code>[service]\ntype = \"metadata\"\nthreads = 2\ncache_size = 1048576  # in bytes\n</code></pre>"},{"location":"services/index.html#future-improvements","title":"Future Improvements","text":"<ul> <li> <p>Configurable key-value backend   Allow the metadata service to be configured to use different key-value stores   (e.g., RocksDB, LevelDB).</p> </li> <li> <p>Metadata deduplication   Deduplicate metadata entries that are shared across multiple layers.</p> </li> </ul>"},{"location":"shared/index.html","title":"Shared Components","text":"<p>The <code>shared/</code> directory contains centralized type definitions, utilities, and common functionality used across all layers and examples in the Modular IO Library.</p>"},{"location":"shared/index.html#directory-structure","title":"Directory Structure","text":"<pre><code>shared/\n\u251c\u2500\u2500 types/           # Core structure definitions\n\u251c\u2500\u2500 enums/           # Enumeration definitions  \n\u251c\u2500\u2500 utils/           # Common utility functions\n\u2502   \u251c\u2500\u2500 conversion/  # Data conversion utilities\n\u2502   \u251c\u2500\u2500 parallel/    # Parallel processing utilities  \n\u2502   \u251c\u2500\u2500 locking/     # Thread-safe locking utilities\n\u2502   \u2514\u2500\u2500 hasher/      # Hash algorithm implementations\n</code></pre>"},{"location":"shared/index.html#components","title":"Components","text":""},{"location":"shared/index.html#core-types-sharedtypes","title":"Core Types (<code>shared/types/</code>)","text":"<p>Fundamental data structures that define the layer architecture:</p> <ul> <li>LayerContext: The primary structure for layer instances</li> <li>LayerOps: Function pointer interface for layer operations</li> <li>Configuration structures: Common configuration patterns</li> </ul> <p>These types provide a uniform interface across all layers and enable layer composition and chaining.</p>"},{"location":"shared/index.html#enumerations-sharedenums","title":"Enumerations (<code>shared/enums/</code>)","text":"<p>Standardized enumeration definitions used throughout the system:</p> <ul> <li>LayerType: Identifies different layer implementations</li> <li>LogMode: Defines logging levels and output modes</li> <li>Algorithm types: Hash algorithms, compression methods, etc.</li> </ul>"},{"location":"shared/index.html#utility-functions-sharedutils","title":"Utility Functions (<code>shared/utils/</code>)","text":""},{"location":"shared/index.html#conversion-utilities","title":"Conversion Utilities","text":"<p>Data format conversion and validation functions:</p> <ul> <li>Type conversion between different data representations</li> <li>Endianness handling for cross-platform compatibility</li> <li>String and numeric conversion utilities</li> </ul>"},{"location":"shared/index.html#parallel-processing-utilities","title":"Parallel Processing Utilities","text":"<p>Thread-safe operations for multi-layer processing:</p> <ul> <li>Thread pool management and coordination</li> <li>Parallel I/O operations</li> <li>Result aggregation from multiple layers</li> </ul>"},{"location":"shared/index.html#locking-utilities","title":"Locking Utilities","text":"<p>Path-based reader-writer locking for concurrent access:</p> <ul> <li>Path-based locking: Locks associated with file paths</li> <li>Reader-writer semantics: Multiple concurrent readers, exclusive writers</li> <li>Automatic cleanup: Prevents lock leaks and deadlocks</li> <li>Efficient lookups: Hash table-based path-to-lock mapping</li> </ul>"},{"location":"shared/index.html#hasher-system","title":"Hasher System","text":"<p>Unified interface for cryptographic hash algorithms:</p> <ul> <li>Generic interface: Algorithm-agnostic hash operations</li> <li>Multiple algorithms: SHA-256, SHA-512 support</li> <li>EVP implementation: Shared OpenSSL operations</li> <li>Runtime selection: Choose algorithms dynamically</li> </ul>"},{"location":"shared/index.html#architecture-principles","title":"Architecture Principles","text":""},{"location":"shared/index.html#thread-safety","title":"Thread Safety","text":"<p>All shared utilities are designed for concurrent use:</p> <ul> <li>Stateless operations where possible</li> <li>Thread-safe synchronization primitives</li> <li>Proper resource management in multi-threaded environments</li> </ul>"},{"location":"shared/index.html#consistency","title":"Consistency","text":"<p>Uniform patterns across the codebase:</p> <ul> <li>Consistent error codes and handling patterns</li> <li>Standardized memory management approaches</li> <li>Common naming conventions and interfaces</li> </ul>"},{"location":"shared/index.html#extensibility","title":"Extensibility","text":"<p>Designed to support future enhancements:</p> <ul> <li>Plugin-style algorithm selection</li> <li>Modular utility organization</li> <li>Clear separation of concerns</li> </ul>"},{"location":"shared/index.html#integration","title":"Integration","text":"<p>Shared components integrate with the layer ecosystem:</p> <ul> <li>All layers: Use core types and enumerations</li> <li>Anti-tampering: Uses hasher system and locking utilities</li> <li>Demultiplexer: Uses parallel processing utilities</li> <li>Configuration: Uses enumerations for validation</li> </ul>"},{"location":"shared/index.html#building","title":"Building","text":"<p>Build shared components:</p> <pre><code># Build shared components\nmake shared/build\n\n# Clean build artifacts\nmake shared/clean\n\n# Run tests\nmake tests/run\n</code></pre>"},{"location":"shared/index.html#usage-guidelines","title":"Usage Guidelines","text":""},{"location":"shared/index.html#for-layer-developers","title":"For Layer Developers","text":"<ul> <li>Use shared types for consistency</li> <li>Follow established error handling patterns</li> <li>Assume multi-threaded usage scenarios</li> <li>Document any extensions to shared interfaces</li> </ul>"},{"location":"shared/index.html#for-application-developers","title":"For Application Developers","text":"<ul> <li>Initialize shared utilities properly</li> <li>Handle resource cleanup appropriately</li> <li>Use thread-safe operations when needed</li> <li>Check return codes for error conditions </li> </ul>"},{"location":"tests/index.html","title":"Tests","text":"<p>The Modular IO Library includes unit tests that validate functionality across the implemented layers and shared components.</p>"},{"location":"tests/index.html#overview","title":"Overview","text":"<p>The test system provides:</p> <ul> <li>Unit tests for individual layers and shared components</li> <li>Automated test execution with make targets  </li> <li>Mock layer infrastructure for testing layer interactions</li> </ul>"},{"location":"tests/index.html#test-architecture","title":"Test Architecture","text":""},{"location":"tests/index.html#directory-structure","title":"Directory Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 Makefile                   # Test build configuration\n\u251c\u2500\u2500 mock_layer.c               # Mock layer implementation for testing\n\u251c\u2500\u2500 mock_layer.h               # Mock layer interface\n\u251c\u2500\u2500 unit/                      # Unit tests\n\u2502   \u251c\u2500\u2500 layers/                # Layer-specific unit tests\n\u2502   \u2502   \u251c\u2500\u2500 anti_tampering/    # Anti-tampering layer tests\n\u2502   \u2502   \u251c\u2500\u2500 block_align/       # Block align layer tests  \n\u2502   \u2502   \u251c\u2500\u2500 compression/       # Compression layer tests\n\u2502   \u2502   \u251c\u2500\u2500 demultiplexer/     # Demultiplexer layer tests\n\u2502   \u2502   \u2514\u2500\u2500 local/             # Local layer tests\n\u2502   \u2514\u2500\u2500 shared/                # Shared components tests\n\u2502       \u2514\u2500\u2500 utils/             # Utility tests\n\u2502           \u251c\u2500\u2500 compressor/    # Compressor algorithm tests\n\u2502           \u2514\u2500\u2500 hasher/        # Hasher algorithm tests\n</code></pre>"},{"location":"tests/index.html#test-framework","title":"Test Framework","text":"<p>The tests use a simple testing approach:</p> <ul> <li>Standard assertions: Uses C's <code>assert()</code> macro</li> <li>Test organization: Each test file contains multiple test functions</li> <li>Main runners: Each test file has a main() function that runs all tests</li> <li>Output format: Console output with pass/fail reporting</li> </ul>"},{"location":"tests/index.html#running-tests","title":"Running Tests","text":""},{"location":"tests/index.html#run-all-tests","title":"Run All Tests","text":"<pre><code># Run complete test suite\nmake tests/run\n</code></pre>"},{"location":"tests/index.html#build-tests-only","title":"Build Tests Only","text":"<pre><code># Build all tests without running\nmake tests/build\n</code></pre>"},{"location":"tests/index.html#clean-test-artifacts","title":"Clean Test Artifacts","text":"<pre><code># Clean all test build artifacts\nmake tests/clean\n</code></pre>"},{"location":"tests/index.html#test-dependencies","title":"Test Dependencies","text":"<p>Tests require external libraries to be built: <pre><code># Ensure all dependencies are built\nmake build        # Build main project including external libraries\nmake tests/run    # Run tests\n</code></pre></p>"},{"location":"tests/index.html#test-areas","title":"Test Areas","text":""},{"location":"tests/index.html#hasher-tests-testsunitsharedutilshasher","title":"Hasher Tests (<code>tests/unit/shared/utils/hasher/</code>)","text":"<p>Tests for the cryptographic hash system:</p> <ul> <li>Generic interface: Common hasher functionality across algorithms</li> <li>Algorithm-specific: SHA-256 and SHA-512 implementations</li> <li>Known test vectors: Validation against expected hash outputs</li> <li>Error handling: Invalid inputs and edge cases</li> </ul>"},{"location":"tests/index.html#layer-tests-testsunitlayers","title":"Layer Tests (<code>tests/unit/layers/</code>)","text":""},{"location":"tests/index.html#local-layer-local","title":"Local Layer (<code>local/</code>)","text":"<p>Tests for local filesystem operations:</p> <ul> <li>Basic file operations and error handling</li> <li>File truncation and size management</li> <li>Permission and access control scenarios</li> </ul>"},{"location":"tests/index.html#anti-tampering-layer-anti_tampering","title":"Anti-Tampering Layer (<code>anti_tampering/</code>)","text":"<p>Tests for data integrity verification:</p> <ul> <li>Hash-based integrity checking</li> <li>File modification detection</li> <li>Hash file management and updates</li> <li>Lock handling and concurrency</li> </ul>"},{"location":"tests/index.html#compression-layer-compression","title":"Compression Layer (<code>compression/</code>)","text":"<p>Tests for data compression functionality:</p> <ul> <li>Main layer tests: Core compression layer operations</li> <li>Configuration: TOML parsing and parameter validation  </li> <li>Compressor engine: Low-level compression/decompression algorithms</li> <li>Algorithm support: LZ4 and ZSTD implementations</li> <li>Round-trip integrity: Data consistency through compress/decompress cycles</li> </ul>"},{"location":"tests/index.html#block-align-layer-block_align","title":"Block Align Layer (<code>block_align/</code>)","text":"<p>Tests for block-aligned I/O operations:</p> <ul> <li>Core functionality: Block boundary handling and alignment</li> <li>Configuration: Block size parsing and validation</li> <li>Cross-block operations: Data spanning multiple blocks</li> <li>Edge cases: Partial blocks and boundary conditions</li> </ul>"},{"location":"tests/index.html#demultiplexer-layer-demultiplexer","title":"Demultiplexer Layer (<code>demultiplexer/</code>)","text":"<p>Tests for parallel multi-backend operations:</p> <ul> <li>Multi-layer coordination and orchestration</li> <li>Enforcement policies for critical vs optional layers</li> <li>Passthrough operation handling</li> <li>Error aggregation across multiple backends</li> </ul>"},{"location":"tests/index.html#test-implementation","title":"Test Implementation","text":""},{"location":"tests/index.html#basic-test-structure","title":"Basic Test Structure","text":"<pre><code>#include &lt;stdio.h&gt;\n#include &lt;assert.h&gt;\n\nvoid test_basic_functionality() {\n    // Test setup\n    int result = some_function(test_input);\n\n    // Assertions\n    assert(result == expected_value);\n    printf(\"test_basic_functionality passed\\n\");\n}\n\nint main() {\n    printf(\"Running unit tests...\\n\\n\");\n\n    test_basic_functionality();\n    // ... more tests ...\n\n    printf(\"\\nAll tests passed!\\n\");\n    return 0;\n}\n</code></pre>"},{"location":"tests/index.html#mock-layer-system","title":"Mock Layer System","text":"<p>The test infrastructure includes a mock layer (<code>mock_layer.c</code>) that simulates layer behavior for testing:</p> <ul> <li>Configurable read/write operations</li> <li>Error injection capabilities</li> <li>State tracking for test verification</li> </ul>"},{"location":"tests/index.html#adding-new-tests","title":"Adding New Tests","text":""},{"location":"tests/index.html#creating-unit-tests","title":"Creating Unit Tests","text":"<ol> <li> <p>Create test file: <pre><code>// tests/unit/my_component/test_my_component.c\n#include \"my_component.h\"\n#include &lt;assert.h&gt;\n#include &lt;stdio.h&gt;\n\nvoid test_my_functionality() {\n    // Test implementation\n    assert(my_function() == expected_result);\n    printf(\"test_my_functionality passed\\n\");\n}\n\nint main() {\n    printf(\"Testing my component...\\n\");\n    test_my_functionality();\n    printf(\"All my component tests passed!\\n\");\n    return 0;\n}\n</code></pre></p> </li> <li> <p>Update Makefile: Add the new test to the <code>UNIT_OBJS</code> and <code>UNIT_BINS</code> variables in <code>tests/Makefile</code> and create the appropriate build rules.</p> </li> <li> <p>Run new tests: <pre><code>make tests/build\nmake tests/run\n</code></pre></p> </li> </ol>"},{"location":"tests/index.html#troubleshooting-tests","title":"Troubleshooting Tests","text":""},{"location":"tests/index.html#common-issues","title":"Common Issues","text":""},{"location":"tests/index.html#test-compilation-errors","title":"Test Compilation Errors","text":"<pre><code># Check dependencies are built\nmake build\n\n# Clean and rebuild tests\nmake tests/clean\nmake tests/build\n</code></pre>"},{"location":"tests/index.html#test-execution-failures","title":"Test Execution Failures","text":"<pre><code># Run specific test for debugging\nbin/tests/layers/local/test_local\n\n# Enable debug logging\nlog_mode = \"debug\"  # in config.toml\n</code></pre>"},{"location":"tests/index.html#debugging-failed-tests","title":"Debugging Failed Tests","text":"<ol> <li>Isolate the failure: Run specific test binaries</li> <li>Enable logging: Use debug logging mode</li> <li>Check dependencies: Verify all required components built</li> <li>Use debugger: Run tests under gdb for detailed analysis</li> </ol> <pre><code># Debug with gdb\ngdb bin/tests/layers/anti_tampering/test_anti_tampering\n(gdb) run\n(gdb) bt  # if it crashes\n</code></pre>"}]}